{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d1dc554-89b4-4b0e-aa68-818103090b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import yaml\n",
    "import sys\n",
    "import h5py\n",
    "import logging\n",
    "import scanpy as sc\n",
    "from os.path import join\n",
    "import scipy.io as sio\n",
    "import scipy.sparse as sps\n",
    "from sklearn.cluster import KMeans\n",
    "import gzip\n",
    "from scipy.io import mmread\n",
    "from pathlib import Path, PurePath\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "def wrap_warn_plot(adata, basis, color, **kwargs):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "        sc.pl.embedding(adata, basis=basis, color=color, **kwargs)\n",
    "\n",
    "def get_umap(ad, use_reps=[]):\n",
    "    for use_rep in use_reps:\n",
    "        umap_add_key = f'{use_rep}_umap'\n",
    "        sc.pp.neighbors(ad, use_rep=use_rep, n_neighbors=15)\n",
    "        sc.tl.umap(ad)\n",
    "        ad.obsm[umap_add_key] = ad.obsm['X_umap']\n",
    "    return ad\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "def split_ob(ads, ad_ref, ob='obs', key='emb2'):\n",
    "    len_ads = [_.n_obs for _ in ads]\n",
    "    if ob=='obsm':\n",
    "        split_obsms = np.split(ad_ref.obsm[key], np.cumsum(len_ads[:-1]))\n",
    "        for ad, v in zip(ads, split_obsms):\n",
    "            ad.obsm[key] = v\n",
    "    else:\n",
    "        split_obs = np.split(ad_ref.obs[key].to_list(), np.cumsum(len_ads[:-1]))\n",
    "        for ad, v in zip(ads, split_obs):\n",
    "            ad.obs[key] = v\n",
    "\n",
    "def eval_ads(ads, ref_key, src_key, exclude=[]):\n",
    "    aris = []\n",
    "    for ad in ads:\n",
    "        _mask = ~ad.obs[ref_key].isin(exclude)\n",
    "        gt = ad.obs[ref_key].values[_mask]\n",
    "        pred = ad.obs[src_key].values[_mask]\n",
    "        aris.append(adjusted_rand_score(pred, gt))\n",
    "    return aris\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "def search_louvain(ad, use_rep, n_neighbors=15, n_clusters=5):\n",
    "    sc.pp.neighbors(ad, n_neighbors=n_neighbors, use_rep=use_rep)\n",
    "    rs = np.arange(0.1, 1.0, 0.1)\n",
    "    n_cs = []\n",
    "    for r in rs:\n",
    "        sc.tl.louvain(ad, resolution=r, key_added=f'r={r}')\n",
    "        n_cs.append(ad.obs[f'r={r}'].nunique())\n",
    "    n_cs = np.array(n_cs)\n",
    "    if (n_cs==n_clusters).sum() >= 1:\n",
    "        ri = np.where(n_cs==n_clusters)[0][0]\n",
    "        ad.obs['louvain_k'] = ad.obs[f'r={rs[ri]}'].to_list()\n",
    "    else:\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(ad.obsm[use_rep])\n",
    "        ad.obs['louvain_k'] = kmeans.labels_.astype('str')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "def eval_labelTransfer(ad1, ad2, use_rep, lab_key, knn=10):\n",
    "     with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "        neigh1 = KNeighborsClassifier(n_neighbors=knn)\n",
    "        neigh1.fit(ad1.obsm[use_rep], ad1.obs[lab_key].to_list())\n",
    "        pr_lab2 = neigh1.predict(ad2.obsm[use_rep])\n",
    "        f1_1 = f1_score(ad2.obs[lab_key].values, pr_lab2, #labels=['1.0', '2.0', '3.0', '4.0'], \n",
    "                        average='macro')\n",
    "        # acc1 = (pr_lab2 == ad2.obs[lab_key].values).mean()\n",
    "    \n",
    "        neigh2 = KNeighborsClassifier(n_neighbors=knn)\n",
    "        neigh2.fit(ad2.obsm[use_rep], ad2.obs[lab_key].to_list())\n",
    "        pr_lab1 = neigh2.predict(ad1.obsm[use_rep])\n",
    "        # acc2 = (pr_lab1 == ad1.obs[lab_key].values).mean()\n",
    "        f1_2 = f1_score(ad1.obs[lab_key].values, pr_lab1, #labels=['1.0', '2.0', '3.0', '4.0'], \n",
    "                        average='macro')\n",
    "        return (f1_1+f1_2)/2\n",
    "\n",
    "from scib.metrics import lisi\n",
    "def eval_lisi(\n",
    "        adata,\n",
    "        batch_keys=['domain', 'batch'],\n",
    "        label_keys = ['gt'],\n",
    "        use_rep='X_emb', use_neighbors=False,\n",
    "    ):\n",
    "    res = {}\n",
    "    for key in batch_keys:\n",
    "        adata.obs[key] = adata.obs[key].astype('category')\n",
    "\n",
    "        _lisi = lisi.ilisi_graph(\n",
    "            adata,\n",
    "            key,\n",
    "            'embed' if not use_neighbors else 'knn',\n",
    "            use_rep=use_rep,\n",
    "            k0=90,\n",
    "            subsample=None,\n",
    "            scale=True,\n",
    "            n_cores=1,\n",
    "            verbose=False,\n",
    "        )\n",
    "        res[key+'_iLISI'] = _lisi\n",
    "    for key in label_keys:\n",
    "        adata.obs[key] = adata.obs[key].astype('category')\n",
    "\n",
    "        _lisi = lisi.clisi_graph(\n",
    "            adata,\n",
    "            key,\n",
    "            'embed' if not use_neighbors else 'knn',\n",
    "            use_rep=use_rep,\n",
    "            batch_key=None,\n",
    "            k0=90,\n",
    "            subsample=None,\n",
    "            scale=True,\n",
    "            n_cores=1,\n",
    "            verbose=False,\n",
    "        )\n",
    "        res[key+'_cLISI'] = _lisi\n",
    "    df = pd.DataFrame.from_dict(res, orient='index').T\n",
    "    # df.columns = [_+'_LISI' for _ in df.columns]\n",
    "    return df\n",
    "\n",
    "os.environ['R_HOME'] = '/disco_500t/xuhua/miniforge3/envs/Seurat5/lib/R'\n",
    "os.environ['R_USER'] = '/disco_500t/xuhua/miniforge3/envs/Seurat5/lib/python3.8/site-packages/rpy2'\n",
    "def mclust_R(adata, num_cluster, modelNames='EEE', used_obsm='STAGATE', random_seed=2020):\n",
    "    np.random.seed(random_seed)\n",
    "    import rpy2.robjects as robjects\n",
    "    robjects.r.library(\"mclust\")\n",
    "\n",
    "    import rpy2.robjects.numpy2ri\n",
    "    rpy2.robjects.numpy2ri.activate()\n",
    "    r_random_seed = robjects.r['set.seed']\n",
    "    r_random_seed(random_seed)\n",
    "    rmclust = robjects.r['Mclust']\n",
    "\n",
    "    res = rmclust(rpy2.robjects.numpy2ri.numpy2rpy(adata.obsm[used_obsm]), num_cluster, modelNames)\n",
    "    mclust_res = np.array(res[-2])\n",
    "\n",
    "    adata.obs['mclust'] = mclust_res\n",
    "    adata.obs['mclust'] = adata.obs['mclust'].astype('int')\n",
    "    adata.obs['mclust'] = adata.obs['mclust'].astype('category')\n",
    "    return adata\n",
    "\n",
    "def load_data(_dir):\n",
    "    feat_names = pd.read_csv(join(_dir, 'features.tsv.gz'), compression='gzip', sep='\\t', header=None)\n",
    "    barcodes   = pd.read_csv(join(_dir, 'barcodes.tsv.gz'), compression='gzip', sep='\\t', header=None)\n",
    "\n",
    "    with gzip.open(join(_dir, 'matrix.mtx.gz'), 'rb') as gzipped_file:\n",
    "        mat = mmread(gzipped_file)\n",
    "\n",
    "    ad = sc.AnnData(sps.csr_matrix(mat.T))\n",
    "    ad.obs_names = barcodes[0].values\n",
    "    ad.var_names = feat_names[1].values\n",
    "    ad.var['id'] = feat_names[0].values\n",
    "    ad.var['type'] = feat_names[2].values\n",
    "    return ad\n",
    "\n",
    "import json\n",
    "import copy\n",
    "from matplotlib.image import imread\n",
    "def load_spatial(path, adata, library_id='0'):\n",
    "    tissue_positions_file = join(path, \"tissue_positions.csv\")\n",
    "    files = dict(\n",
    "        tissue_positions_file=tissue_positions_file,\n",
    "        scalefactors_json_file=join(path, \"scalefactors_json.json\"),\n",
    "        hires_image=join(path, \"tissue_hires_image.png\"),\n",
    "        lowres_image=join(path, \"tissue_lowres_image.png\"),\n",
    "    )\n",
    "    \n",
    "    adata.uns[\"spatial\"] = dict()\n",
    "    adata.uns[\"spatial\"][library_id] = dict()\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"] = dict()\n",
    "    for res in [\"hires\", \"lowres\"]:\n",
    "        try:\n",
    "            adata.uns[\"spatial\"][library_id][\"images\"][res] = imread(\n",
    "                str(files[f\"{res}_image\"])\n",
    "            )\n",
    "        except Exception:\n",
    "            raise OSError(f\"Could not find '{res}_image'\")\n",
    "\n",
    "    # read json scalefactors\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"] = json.loads(\n",
    "        Path(files[\"scalefactors_json_file\"]).read_bytes()\n",
    "    )\n",
    "\n",
    "    # adata.uns[\"spatial\"][library_id][\"metadata\"] = {\n",
    "    #     k: (str(attrs[k], \"utf-8\") if isinstance(attrs[k], bytes) else attrs[k])\n",
    "    #     for k in (\"chemistry_description\", \"software_version\")\n",
    "    #     if k in attrs\n",
    "    # }\n",
    "\n",
    "    # read coordinates\n",
    "    positions = pd.read_csv(\n",
    "        files[\"tissue_positions_file\"],\n",
    "        header=0 if Path(tissue_positions_file).name == \"tissue_positions.csv\" else None,\n",
    "        index_col=0,\n",
    "    )\n",
    "    positions.columns = [\n",
    "        \"in_tissue\",\n",
    "        \"array_row\",\n",
    "        \"array_col\",\n",
    "        \"pxl_col_in_fullres\",\n",
    "        \"pxl_row_in_fullres\",\n",
    "    ]\n",
    "    # print(positions.head())\n",
    "\n",
    "    adata.obs = adata.obs.join(positions, how=\"left\")\n",
    "\n",
    "    adata.obsm[\"spatial\"] = adata.obs[\n",
    "        [\"pxl_row_in_fullres\", \"pxl_col_in_fullres\"]\n",
    "    ].to_numpy()\n",
    "   \n",
    "    adata.obs.drop(\n",
    "        columns=[\"pxl_row_in_fullres\", \"pxl_col_in_fullres\"],\n",
    "        inplace=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19d8714e-be84-4896-8f6f-75574c3c536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col2cat(ad, cols=[]):\n",
    "    for col in cols:\n",
    "        ad.obs[col] = ad.obs[col].astype('category')\n",
    "\n",
    "def unify_colors(queries, color_key, ref_color_dict):\n",
    "    for q in queries:\n",
    "        q.obs[color_key] = q.obs[color_key].astype('category')\n",
    "        q.uns[f'{color_key}_colors'] = [ref_color_dict[_] for _ in q.obs[color_key].cat.categories]\n",
    "    return queries\n",
    "\n",
    "def subset_ad(ad, subset_index):\n",
    "    ad = ad[subset_index].copy()\n",
    "    return ad\n",
    "\n",
    "def set_spatial(ad):\n",
    "    ad.obsm['spatial'] = ad.obs[['array_row', 'array_col']].values\n",
    "    ad.obsm['spatial'] = ad.obsm['spatial'][:, ::-1]\n",
    "    ad.obsm['spatial'][:, 1] = -1 * ad.obsm['spatial'][:, 1]\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6706ddae-3067-4647-b21c-7a4e01fa3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_zu(_dir):\n",
    "    zs = []\n",
    "\n",
    "    for fi in sorted(os.listdir(_dir)):\n",
    "        dfi = pd.read_csv(join(_dir, fi), header=None)\n",
    "        zs.append(dfi.values)\n",
    "    zs = np.vstack(zs)\n",
    "    z, u = zs[:, :-2], zs[:, -2:]\n",
    "    return z, u\n",
    "\n",
    "def wrap_warn_plot(adata, basis, color, **kwargs):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "        sc.pl.embedding(adata, basis=basis, color=color, **kwargs)\n",
    "\n",
    "def get_umap(ad, use_reps=[]):\n",
    "    for use_rep in use_reps:\n",
    "        umap_add_key = f'{use_rep}_umap'\n",
    "        sc.pp.neighbors(ad, use_rep=use_rep, n_neighbors=15)\n",
    "        sc.tl.umap(ad)\n",
    "        ad.obsm[umap_add_key] = ad.obsm['X_umap']\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f60e017-d0b4-4a17-b9de-7a0a0bbf67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = '/disco_500t/xuhua/gitrepo/midas/result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bec33661-beda-4631-bda0-694a7a0f7584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/disco_500t/xuhua/data/spatial_multi_omics/lymp_node/LN-2024-new/outs'\n",
    "\n",
    "ad3 = load_data(join(data_dir, 'filtered_feature_bc_matrix'))\n",
    "ad3_rna = ad3[:, ad3.var['type']=='Gene Expression'].copy()\n",
    "ad3_adt = ad3[:, ad3.var['type']=='Antibody Capture'].copy()\n",
    "load_spatial(join(data_dir, 'spatial'), ad3_rna)\n",
    "load_spatial(join(data_dir, 'spatial'), ad3_adt)\n",
    "\n",
    "ad3_rna.obs['src'] = ad3_adt.obs['src'] = ['s3']*ad3_rna.n_obs\n",
    "ad3_rna.obs_names = [f's3-{x}' for x in ad3_rna.obs_names]\n",
    "ad3_adt.obs_names = [f's3-{x}' for x in ad3_adt.obs_names]\n",
    "\n",
    "ad3_rna.var_names_make_unique()\n",
    "ad3_adt.var_names_make_unique()\n",
    "\n",
    "data_dir = '/disco_500t/xuhua/data/spatial_multi_omics/lymp_tonsil_ramen'\n",
    "\n",
    "ad_a1_rna = sc.read_h5ad(join(data_dir, 'lymph_A1/adata_RNA.h5ad'))\n",
    "ad_a1_adt = sc.read_h5ad(join(data_dir, 'lymph_A1/adata_ADT.h5ad'))\n",
    "meta1 = pd.read_csv(join(data_dir, 'lymph_A1/A1_LN_cloupe_Kwoh.csv'), index_col=0) \n",
    "ad_a1_rna.obs['lab'] = meta1.loc[ad_a1_rna.obs_names, 'manual'].to_list()\n",
    "ad_a1_adt.obs['lab'] = meta1.loc[ad_a1_adt.obs_names, 'manual'].to_list()\n",
    "ad_a1_rna.obs['src'] = ad_a1_adt.obs['src'] = ['s1'] * ad_a1_rna.n_obs\n",
    "ad_a1_rna.obs_names = [f's1-{x}' for x in ad_a1_rna.obs_names]\n",
    "ad_a1_adt.obs_names = [f's1-{x}' for x in ad_a1_adt.obs_names]\n",
    "ad_a1_rna.obs['Sample'] = ad_a1_adt.obs['Sample'] = ['S1']*ad_a1_rna.n_obs\n",
    "ad_a1_rna.var_names_make_unique()\n",
    "ad_a1_adt.var_names_make_unique()\n",
    "\n",
    "ad_d1_rna = sc.read_h5ad(join(data_dir, 'lymph_D1/adata_RNA.h5ad'))\n",
    "ad_d1_adt = sc.read_h5ad(join(data_dir, 'lymph_D1/adata_ADT.h5ad'))\n",
    "meta2 = pd.read_csv(join(data_dir, 'lymph_D1/D1_LN_cloupe_Kwoh.csv'), index_col=0) \n",
    "ad_d1_rna.obs['lab'] = meta2.loc[ad_d1_rna.obs_names, 'manual'].to_list()\n",
    "ad_d1_adt.obs['lab'] = meta2.loc[ad_d1_adt.obs_names, 'manual'].to_list()\n",
    "ad_d1_rna.obs['src'] = ['s2-rna'] * ad_d1_rna.n_obs\n",
    "ad_d1_adt.obs['src'] = ['s2-adt'] * ad_d1_adt.n_obs\n",
    "ad_d1_rna.obs_names = [f's2-rna-{x}' for x in ad_d1_rna.obs_names]\n",
    "ad_d1_adt.obs_names = [f's2-adt-{x}' for x in ad_d1_adt.obs_names]\n",
    "ad_d1_rna.obs['Sample'] = ad_d1_adt.obs['Sample'] = ['S2']*ad_d1_rna.n_obs\n",
    "ad_d1_rna.var_names_make_unique()\n",
    "ad_d1_adt.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34b2f40d-ff3c-4849-9a4c-733742e563d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_rna_all = sc.concat([ad_a1_rna, ad_d1_rna, ad3_rna])\n",
    "ad_adt_all = sc.concat([ad_a1_adt, ad_d1_adt, ad3_adt])\n",
    "\n",
    "sc.pp.highly_variable_genes(ad_rna_all, flavor='seurat_v3', n_top_genes=10000, batch_key='src')\n",
    "hvg_names = ad_rna_all.var.query('highly_variable').index.to_numpy()\n",
    "hvp_names = ad_adt_all.var_names.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31caae0c-5deb-4d02-9a97-e0fa8dde62c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### save data\n",
    "input_train_mod1 = ad_a1_rna[:, hvg_names].copy()\n",
    "input_train_mod2 = ad_a1_adt[:, hvp_names].copy()\n",
    "input_test_mod1 = ad_d1_rna[:, hvg_names].copy()\n",
    "input_test_mod2 = ad_d1_adt[:, hvp_names].copy()\n",
    "\n",
    "tmp_out_dir = f'/disco_500t/xuhua/gitrepo/midas/data/processed/Lymph_modalMatch'\n",
    "feat_dir = join(tmp_out_dir, 'feat')\n",
    "os.makedirs(feat_dir, exist_ok=True)\n",
    "\n",
    "df_feat_dims = pd.DataFrame(np.array([input_train_mod1.n_vars, input_train_mod2.n_vars]).reshape(1, -1), columns=['rna', 'adt'])\n",
    "df_feat_rna_names = pd.DataFrame(input_train_mod1.var_names, columns=['x'])\n",
    "df_feat_adt_names = pd.DataFrame(input_train_mod2.var_names, columns=['x'])\n",
    "df_feat_dims.to_csv(join(feat_dir, 'feat_dims.csv'))\n",
    "df_feat_rna_names.to_csv(join(feat_dir, 'feat_names_rna.csv'))\n",
    "df_feat_adt_names.to_csv(join(feat_dir, 'feat_names_adt.csv'))\n",
    "\n",
    "# each subset\n",
    "subsets = [[input_train_mod1, input_train_mod2], [input_test_mod1], [input_test_mod2]]\n",
    "mods = [['rna', 'adt'], ['rna'], ['adt']]\n",
    "\n",
    "for si in range(3):\n",
    "    for fname in ['mask', 'mat', 'vec']:\n",
    "        os.makedirs(join(tmp_out_dir, f'subset_{si}/{fname}'), exist_ok=True)\n",
    "    tmp_dir = join(tmp_out_dir, f'subset_{si}')\n",
    "    for ad,mi in zip(subsets[si], mods[si]):\n",
    "        mat = ad.X.A if sps.issparse(ad.X) else ad.X\n",
    "        df_mat = pd.DataFrame(mat, index=ad.obs_names, columns=ad.var_names)\n",
    "        df_mat.to_csv(join(tmp_dir, f'mat/{mi}.csv'))\n",
    "\n",
    "        os.makedirs(join(tmp_dir, f'vec/{mi}'), exist_ok=True)\n",
    "        for idx, mati in enumerate(mat):\n",
    "            pd.DataFrame(mati.reshape(1, -1)).to_csv(join(tmp_dir, 'vec/{}/{:05d}.csv'.format(mi, idx)), header=None, index=None)\n",
    "        pd.DataFrame(ad.obs_names, columns=['x']).to_csv(join(tmp_dir, 'cell_names.csv'))\n",
    "\n",
    "        # save mask\n",
    "        pd.DataFrame(np.ones(ad.n_vars, dtype='int')).to_csv(join(tmp_dir, f'mask/{mi}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f0101ee-e487-4c09-81a5-a4ab37d9326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e, ep in enumerate([2000], 1):\n",
    "    training_command = f'CUDA_VISIBLE_DEVICES=2 python run.py --exp e{e} --task Lymph_modalMatch --epoch_num {ep}'\n",
    "\n",
    "    run_command = 'CUDA_VISIBLE_DEVICES=2 python run.py --task Lymph_modalMatch --act predict_all_latent_bc --init_model sp_{:08d} --exp e{}'\\\n",
    "                                .format(ep-1, e)\n",
    "    print(training_command)\n",
    "    print(run_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0e9e7a8-1a25-4c09-92e0-911a793a9c6e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e, ep = 1, 2000\n",
    "model_pt = 'sp_{:08d}'.format(ep-1)\n",
    "\n",
    "tmp_dir = f'{result_dir}/Lymph_modalMatch/e{e}/default/predict/{model_pt}'\n",
    "target_ads = [ad_a1_rna, ad_d1_rna, ad_d1_adt]\n",
    "for i in range(3):\n",
    "    z, u = load_zu(join(tmp_dir, f'subset_{i}/z/joint'))\n",
    "    target_ads[i].obsm['z'] = z\n",
    "    target_ads[i].obsm['u'] = u\n",
    "    \n",
    "ad_mosaic = sc.concat(target_ads)\n",
    "# ad_mosaic = get_umap(ad_mosaic, ['z'])\n",
    "\n",
    "# wrap_warn_plot(ad_mosaic, 'z_umap', ['src'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a711ec6-0595-47a0-82e2-9f1245210d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lisi_res = eval_lisi(\n",
    "#     ad_mosaic,\n",
    "#     batch_keys=['src'],\n",
    "#     label_keys = [],\n",
    "#     use_rep='z', use_neighbors=False,\n",
    "# )\n",
    "# lisi_res['src_iLISI'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "637baf6b-2670-48b2-80f6-082fc9da870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOSCTTM=0.15921\n",
      "Match_score=0.00806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'FOSCTTM': 0.15921141949471945, 'Match_score': 0.008055119392746137}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lisi_bridge import eval_bridge\n",
    "eval_bridge(\n",
    "        ad_d1_rna, ad_d1_adt,\n",
    "        label_key=None,\n",
    "        batch_key='Sample',\n",
    "        use_rep='z',\n",
    "        use_fosc=True, use_acc=False, use_score=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd740f90-e0fa-4159-9a77-2cd95ac795de",
   "metadata": {},
   "source": [
    "### batch corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf84b19b-2756-44d6-8e7c-fcbedf5585c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU mode.\n",
      "\tInitialization is completed.\n",
      "\tCompleted 1 / 10 iteration(s).\n",
      "\tCompleted 2 / 10 iteration(s).\n",
      "\tCompleted 3 / 10 iteration(s).\n",
      "\tCompleted 4 / 10 iteration(s).\n",
      "\tCompleted 5 / 10 iteration(s).\n",
      "Reach convergence after 5 iteration(s).\n"
     ]
    }
   ],
   "source": [
    "from batchCorr import HARMONY\n",
    "\n",
    "ad_mosaic.obsm['z_har'] = HARMONY(pd.DataFrame(ad_mosaic.obsm['z']), ad_mosaic.obs['src'].to_list())\n",
    "split_ob([ad_a1_rna, ad_d1_rna, ad_d1_adt], ad_mosaic, ob='obsm', key='z_har')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e1de0ae-b4e1-4cec-b471-a1dc1c0b2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lisi_res = eval_lisi(\n",
    "#     ad_mosaic,\n",
    "#     batch_keys=['src'],\n",
    "#     label_keys = [],\n",
    "#     use_rep='z_har', use_neighbors=False,\n",
    "# )\n",
    "# lisi_res['src_iLISI'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "663eb4bb-79c8-409e-a4d9-82b554dfad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOSCTTM=0.14225\n",
      "Match_score=0.01146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'FOSCTTM': 0.14224948397488194, 'Match_score': 0.011455493994940258}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_bridge(\n",
    "        ad_d1_rna, ad_d1_adt,\n",
    "        label_key=None,\n",
    "        batch_key='Sample',\n",
    "        use_rep='z_har',\n",
    "        use_fosc=True, use_acc=False, use_score=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5079f1c4-60fe-4e3f-a31e-e3119461192a",
   "metadata": {},
   "source": [
    "## Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4f389d9-9992-46ed-ac5c-5b2f109daf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = f'/disco_500t/xuhua/gitrepo/BridgeNorm/figures/Lymph_modalMatch/midas'\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame(ad_mosaic.obsm['z'], index=ad_mosaic.obs_names.to_list())\n",
    "# df['before_clust'] = ad_mosaic.obs['before_clust'].to_list() \n",
    "df.to_csv(join(fig_dir, 'X_emb.csv'))\n",
    "\n",
    "df = pd.DataFrame(ad_mosaic.obsm['z_har'], index=ad_mosaic.obs_names.to_list())\n",
    "# df['after_clust'] = ad_mosaic.obs['after_clust'].to_list() \n",
    "df.to_csv(join(fig_dir, 'X_emb_har.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a825bcb-2e00-4845-8f2a-7f7d29bd4bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ad9f19-e901-414f-b085-a4ca3b4f0c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Squidpy",
   "language": "python",
   "name": "squidpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
