{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf4aea00-9a9d-43af-bd0c-4c3e8d8ce5ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "import numpy as np\n",
    "from umap import UMAP\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  \n",
    "import scanpy as sc\n",
    "import scipy.sparse as sps\n",
    "import scipy.io as sio\n",
    "# import scipy.sparse as sp\n",
    "from os.path import join\n",
    "import h5py\n",
    "import warnings\n",
    "import gc\n",
    "from postp import HARMONY\n",
    "\n",
    "import gzip\n",
    "from scipy.io import mmread\n",
    "from pathlib import Path, PurePath\n",
    "from sklearn.metrics import adjusted_rand_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f64d1d4f-1353-44b0-a051-a0a4700ad711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col2cat(ad, cols=[]):\n",
    "    for col in cols:\n",
    "        ad.obs[col] = ad.obs[col].astype('category')\n",
    "\n",
    "def unify_colors(queries, color_key, ref_color_dict):\n",
    "    for q in queries:\n",
    "        q.obs[color_key] = q.obs[color_key].astype('category')\n",
    "        q.uns[f'{color_key}_colors'] = [ref_color_dict[_] for _ in q.obs[color_key].cat.categories]\n",
    "    return queries\n",
    "\n",
    "def get_umap(ad, use_reps=[]):\n",
    "    for use_rep in use_reps:\n",
    "        umap_add_key = f'{use_rep}_umap'\n",
    "        sc.pp.neighbors(ad, use_rep=use_rep, n_neighbors=15)\n",
    "        sc.tl.umap(ad)\n",
    "        ad.obsm[umap_add_key] = ad.obsm['X_umap']\n",
    "    return ad\n",
    "\n",
    "def wrap_warn_plot(adata, basis, color, **kwargs):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "        sc.pl.embedding(adata, basis=basis, color=color, **kwargs)\n",
    "\n",
    "def wrap_warn_comp_plot(ads, basis, colors, figw=5, figh=4, **kwargs):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        for i, color in enumerate(colors):\n",
    "            _, axes = plt.subplots(1, len(ads), figsize=(figw*len(ads), figh))\n",
    "            for j, ad in enumerate(ads):\n",
    "                sc.pl.embedding(ad, basis=basis, color=color, ax=axes[j], show=False, **kwargs)\n",
    "            plt.show()\n",
    "            \n",
    "os.environ['R_HOME'] = '/disco_500t/xuhua/miniforge3/envs/Seurat5/lib/R'\n",
    "os.environ['R_USER'] = '/disco_500t/xuhua/miniforge3/envs/Seurat5/lib/python3.8/site-packages/rpy2'\n",
    "def mclust_R(adata, num_cluster, modelNames='EEE', used_obsm='STAGATE', random_seed=2020):\n",
    "    np.random.seed(random_seed)\n",
    "    import rpy2.robjects as robjects\n",
    "    robjects.r.library(\"mclust\")\n",
    "\n",
    "    import rpy2.robjects.numpy2ri\n",
    "    rpy2.robjects.numpy2ri.activate()\n",
    "    r_random_seed = robjects.r['set.seed']\n",
    "    r_random_seed(random_seed)\n",
    "    rmclust = robjects.r['Mclust']\n",
    "\n",
    "    res = rmclust(rpy2.robjects.numpy2ri.numpy2rpy(adata.obsm[used_obsm]), num_cluster, modelNames)\n",
    "    mclust_res = np.array(res[-2])\n",
    "\n",
    "    adata.obs['mclust'] = mclust_res\n",
    "    adata.obs['mclust'] = adata.obs['mclust'].astype('int')\n",
    "    adata.obs['mclust'] = adata.obs['mclust'].astype('category')\n",
    "    return adata\n",
    "    \n",
    "def load_data(_dir):\n",
    "    feat_names = pd.read_csv(join(_dir, 'features.tsv.gz'), compression='gzip', sep='\\t', header=None)\n",
    "    barcodes   = pd.read_csv(join(_dir, 'barcodes.tsv.gz'), compression='gzip', sep='\\t', header=None)\n",
    "\n",
    "    with gzip.open(join(_dir, 'matrix.mtx.gz'), 'rb') as gzipped_file:\n",
    "        mat = mmread(gzipped_file)\n",
    "\n",
    "    ad = sc.AnnData(sps.csr_matrix(mat.T))\n",
    "    ad.obs_names = barcodes[0].values\n",
    "    ad.var_names = feat_names[1].values\n",
    "    ad.var['id'] = feat_names[0].values\n",
    "    ad.var['type'] = feat_names[2].values\n",
    "    return ad\n",
    "\n",
    "\n",
    "import json\n",
    "import copy\n",
    "from matplotlib.image import imread\n",
    "def load_spatial(path, adata, library_id='0'):\n",
    "    tissue_positions_file = join(path, \"tissue_positions.csv\")\n",
    "    files = dict(\n",
    "        tissue_positions_file=tissue_positions_file,\n",
    "        scalefactors_json_file=join(path, \"scalefactors_json.json\"),\n",
    "        hires_image=join(path, \"tissue_hires_image.png\"),\n",
    "        lowres_image=join(path, \"tissue_lowres_image.png\"),\n",
    "    )\n",
    "    \n",
    "    adata.uns[\"spatial\"] = dict()\n",
    "    adata.uns[\"spatial\"][library_id] = dict()\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"] = dict()\n",
    "    for res in [\"hires\", \"lowres\"]:\n",
    "        try:\n",
    "            adata.uns[\"spatial\"][library_id][\"images\"][res] = imread(\n",
    "                str(files[f\"{res}_image\"])\n",
    "            )\n",
    "        except Exception:\n",
    "            raise OSError(f\"Could not find '{res}_image'\")\n",
    "\n",
    "    # read json scalefactors\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"] = json.loads(\n",
    "        Path(files[\"scalefactors_json_file\"]).read_bytes()\n",
    "    )\n",
    "\n",
    "    # adata.uns[\"spatial\"][library_id][\"metadata\"] = {\n",
    "    #     k: (str(attrs[k], \"utf-8\") if isinstance(attrs[k], bytes) else attrs[k])\n",
    "    #     for k in (\"chemistry_description\", \"software_version\")\n",
    "    #     if k in attrs\n",
    "    # }\n",
    "\n",
    "    # read coordinates\n",
    "    positions = pd.read_csv(\n",
    "        files[\"tissue_positions_file\"],\n",
    "        header=0 if Path(tissue_positions_file).name == \"tissue_positions.csv\" else None,\n",
    "        index_col=0,\n",
    "    )\n",
    "    positions.columns = [\n",
    "        \"in_tissue\",\n",
    "        \"array_row\",\n",
    "        \"array_col\",\n",
    "        \"pxl_col_in_fullres\",\n",
    "        \"pxl_row_in_fullres\",\n",
    "    ]\n",
    "    # print(positions.head())\n",
    "\n",
    "    adata.obs = adata.obs.join(positions, how=\"left\")\n",
    "\n",
    "    adata.obsm[\"spatial\"] = adata.obs[\n",
    "        [\"pxl_row_in_fullres\", \"pxl_col_in_fullres\"]\n",
    "    ].to_numpy()\n",
    "   \n",
    "    adata.obs.drop(\n",
    "        columns=[\"pxl_row_in_fullres\", \"pxl_col_in_fullres\"],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "from scib.metrics import lisi\n",
    "def eval_lisi(\n",
    "        adata,\n",
    "        batch_keys=['domain', 'batch'],\n",
    "        label_keys = ['gt'],\n",
    "        use_rep='X_emb', use_neighbors=False,\n",
    "    ):\n",
    "    res = {}\n",
    "    for key in batch_keys:\n",
    "        adata.obs[key] = adata.obs[key].astype('category')\n",
    "\n",
    "        _lisi = lisi.ilisi_graph(\n",
    "            adata,\n",
    "            key,\n",
    "            'embed' if not use_neighbors else 'knn',\n",
    "            use_rep=use_rep,\n",
    "            k0=90,\n",
    "            subsample=None,\n",
    "            scale=True,\n",
    "            n_cores=1,\n",
    "            verbose=False,\n",
    "        )\n",
    "        res[key+'_iLISI'] = _lisi\n",
    "    for key in label_keys:\n",
    "        adata.obs[key] = adata.obs[key].astype('category')\n",
    "\n",
    "        _lisi = lisi.clisi_graph(\n",
    "            adata,\n",
    "            key,\n",
    "            'embed' if not use_neighbors else 'knn',\n",
    "            use_rep=use_rep,\n",
    "            batch_key=None,\n",
    "            k0=90,\n",
    "            subsample=None,\n",
    "            scale=True,\n",
    "            n_cores=1,\n",
    "            verbose=False,\n",
    "        )\n",
    "        res[key+'_cLISI'] = _lisi\n",
    "    df = pd.DataFrame.from_dict(res, orient='index').T\n",
    "    # df.columns = [_+'_LISI' for _ in df.columns]\n",
    "    return df\n",
    "\n",
    "def eval_ads(ads, ref_key, src_key, exclude=[]):\n",
    "    aris = []\n",
    "    for ad in ads:\n",
    "        _mask = ~ad.obs[ref_key].isin(exclude)\n",
    "        gt = ad.obs[ref_key].values[_mask]\n",
    "        pred = ad.obs[src_key].values[_mask]\n",
    "        aris.append(adjusted_rand_score(pred, gt))\n",
    "    return aris\n",
    "    \n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c9b2b5a-0d42-4ce6-b991-4f91f9382a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ob(ads, ad_ref, ob='obs', key='emb2'):\n",
    "    len_ads = [_.n_obs for _ in ads]\n",
    "    if ob=='obsm':\n",
    "        split_obsms = np.split(ad_ref.obsm[key], np.cumsum(len_ads[:-1]))\n",
    "        for ad, v in zip(ads, split_obsms):\n",
    "            ad.obsm[key] = v\n",
    "    else:\n",
    "        split_obs = np.split(ad_ref.obs[key].to_list(), np.cumsum(len_ads[:-1]))\n",
    "        for ad, v in zip(ads, split_obs):\n",
    "            ad.obs[key] = v\n",
    "    \n",
    "def subset_ad(ad, subset_index):\n",
    "    ad = ad[subset_index].copy()\n",
    "    return ad\n",
    "\n",
    "def set_spatial(ad):\n",
    "    ad.obsm['spatial'] = ad.obs[['array_row', 'array_col']].values\n",
    "    ad.obsm['spatial'] = ad.obsm['spatial'][:, ::-1]\n",
    "    ad.obsm['spatial'][:, 1] = -1 * ad.obsm['spatial'][:, 1]\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b399a-ad73-48bf-9161-7b4ebec63718",
   "metadata": {},
   "source": [
    "### load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "056e1b54-a443-41bf-aa3d-5ff645238a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/disco_500t/xuhua/data/spatial_multi_omics/lymp_node/LN-2024-new/outs'\n",
    "\n",
    "ad3 = load_data(join(data_dir, 'filtered_feature_bc_matrix'))\n",
    "ad3_rna = ad3[:, ad3.var['type']=='Gene Expression'].copy()\n",
    "ad3_adt = ad3[:, ad3.var['type']=='Antibody Capture'].copy()\n",
    "load_spatial(join(data_dir, 'spatial'), ad3_rna)\n",
    "load_spatial(join(data_dir, 'spatial'), ad3_adt)\n",
    "\n",
    "ad3_rna.obs['src'] = ad3_adt.obs['src'] = ['s3']*ad3_rna.n_obs\n",
    "ad3_rna.obs_names = [f's3-{x}' for x in ad3_rna.obs_names]\n",
    "ad3_adt.obs_names = [f's3-{x}' for x in ad3_adt.obs_names]\n",
    "\n",
    "ad3_rna.var_names_make_unique()\n",
    "ad3_adt.var_names_make_unique()\n",
    "\n",
    "data_dir = '/disco_500t/xuhua/data/spatial_multi_omics/lymp_tonsil_ramen'\n",
    "\n",
    "ad_a1_rna = sc.read_h5ad(join(data_dir, 'lymph_A1/adata_RNA.h5ad'))\n",
    "ad_a1_adt = sc.read_h5ad(join(data_dir, 'lymph_A1/adata_ADT.h5ad'))\n",
    "meta1 = pd.read_csv(join(data_dir, 'lymph_A1/A1_LN_cloupe_Kwoh.csv'), index_col=0) \n",
    "ad_a1_rna.obs['lab'] = meta1.loc[ad_a1_rna.obs_names, 'manual'].to_list()\n",
    "ad_a1_adt.obs['lab'] = meta1.loc[ad_a1_adt.obs_names, 'manual'].to_list()\n",
    "ad_a1_rna.obs['src'] = ad_a1_adt.obs['src'] = ['s1'] * ad_a1_rna.n_obs\n",
    "ad_a1_rna.obs_names = [f's1-{x}' for x in ad_a1_rna.obs_names]\n",
    "ad_a1_adt.obs_names = [f's1-{x}' for x in ad_a1_adt.obs_names]\n",
    "ad_a1_rna.var_names_make_unique()\n",
    "ad_a1_adt.var_names_make_unique()\n",
    "\n",
    "ad_d1_rna = sc.read_h5ad(join(data_dir, 'lymph_D1/adata_RNA.h5ad'))\n",
    "ad_d1_adt = sc.read_h5ad(join(data_dir, 'lymph_D1/adata_ADT.h5ad'))\n",
    "meta2 = pd.read_csv(join(data_dir, 'lymph_D1/D1_LN_cloupe_Kwoh.csv'), index_col=0) \n",
    "ad_d1_rna.obs['lab'] = meta2.loc[ad_d1_rna.obs_names, 'manual'].to_list()\n",
    "ad_d1_adt.obs['lab'] = meta2.loc[ad_d1_adt.obs_names, 'manual'].to_list()\n",
    "ad_d1_rna.obs['src'] = ad_d1_adt.obs['src'] = ['s2'] * ad_d1_rna.n_obs\n",
    "ad_d1_rna.obs_names = [f's2-{x}' for x in ad_d1_rna.obs_names]\n",
    "ad_d1_adt.obs_names = [f's2-{x}' for x in ad_d1_adt.obs_names]\n",
    "ad_d1_rna.var_names_make_unique()\n",
    "ad_d1_adt.var_names_make_unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "552ed9e5-1298-48e4-ad2f-772a9d1e28c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./outputs/lymph.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31bcc82f-b3af-46d3-be77-c6d7d07d4290",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ad_a1_rna.obsm['emb'] = df.loc[ad_a1_rna.obs_names].values\n",
    "ad_a1_adt.obsm['emb'] = df.loc[ad_a1_adt.obs_names].values\n",
    "ad_d1_adt.obsm['emb'] = df.loc[ad_d1_adt.obs_names].values\n",
    "ad3_adt.obsm['emb'] = df.loc[ad3_adt.obs_names].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b3d144-cd55-4ac8-a93e-4832f4e412b5",
   "metadata": {},
   "source": [
    "### before harmony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35e83ebb-cacd-4539-b878-bdac3e3743da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_mosaic = sc.concat([ad_a1_adt, ad_d1_adt, ad3_adt])\n",
    "ad_mosaic = get_umap(ad_mosaic, ['emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4e9449a-a3fc-4b57-b6e2-2332ea72843f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4503979506114927"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lisi_res = eval_lisi(\n",
    "    ad_mosaic,\n",
    "    batch_keys=['src'],\n",
    "    label_keys = [],\n",
    "    use_rep='emb', use_neighbors=False,\n",
    ")\n",
    "lisi_res['src_iLISI'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b8d10c-0a95-4119-8781-c1ff6c2ccf3f",
   "metadata": {},
   "source": [
    "## after harmony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0bec2f0-4671-48c9-99df-94e516f20a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU mode.\n",
      "\tInitialization is completed.\n",
      "\tCompleted 1 / 10 iteration(s).\n",
      "\tCompleted 2 / 10 iteration(s).\n",
      "\tCompleted 3 / 10 iteration(s).\n",
      "\tCompleted 4 / 10 iteration(s).\n",
      "\tCompleted 5 / 10 iteration(s).\n",
      "\tCompleted 6 / 10 iteration(s).\n",
      "Reach convergence after 6 iteration(s).\n"
     ]
    }
   ],
   "source": [
    "from postp import HARMONY\n",
    "\n",
    "ad_mosaic.obsm['emb_har'] = HARMONY(pd.DataFrame(ad_mosaic.obsm['emb']), ad_mosaic.obs.src.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56f3c08d-c696-45d8-bbf5-640812fc9503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42243574776906645"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lisi_res = eval_lisi(\n",
    "    ad_mosaic,\n",
    "    batch_keys=['src'],\n",
    "    label_keys = [],\n",
    "    use_rep='emb_har', use_neighbors=False,\n",
    ")\n",
    "lisi_res['src_iLISI'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9befad2f-945e-4d9d-a981-b405cbb4d0a5",
   "metadata": {},
   "source": [
    "## Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40e4921f-54cf-4d08-ba86-dc831d3e8772",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = f'/disco_500t/xuhua/gitrepo/BridgeNorm/figures/Lymph_3slices_fuck/stabmap'\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame(ad_mosaic.obsm['emb'], index=ad_mosaic.obs_names)\n",
    "# df['before_clust'] = ad_mosaic.obs['before_clust'].to_list() \n",
    "df.to_csv(join(fig_dir, 'X_emb.csv'))\n",
    "\n",
    "df = pd.DataFrame(ad_mosaic.obsm['emb_har'], index=ad_mosaic.obs_names)\n",
    "# df['after_clust'] = ad_mosaic.obs['after_clust'].to_list() \n",
    "df.to_csv(join(fig_dir, 'X_emb_har.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205d6090-6ec5-4548-bdeb-0162950d9a2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Squidpy",
   "language": "python",
   "name": "squidpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
