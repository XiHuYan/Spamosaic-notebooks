{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf4aea00-9a9d-43af-bd0c-4c3e8d8ce5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "\n",
    "import numpy as np\n",
    "from umap import UMAP\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd  \n",
    "import scanpy as sc\n",
    "import scipy.sparse as sps\n",
    "import scipy.io as sio\n",
    "# import scipy.sparse as sp\n",
    "from os.path import join\n",
    "import h5py\n",
    "import warnings\n",
    "import gc\n",
    "from postp import HARMONY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f64d1d4f-1353-44b0-a051-a0a4700ad711",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col2cat(ad, cols=[]):\n",
    "    for col in cols:\n",
    "        ad.obs[col] = ad.obs[col].astype('category')\n",
    "\n",
    "def unify_colors(queries, color_key, ref_color_dict):\n",
    "    for q in queries:\n",
    "        q.obs[color_key] = q.obs[color_key].astype('category')\n",
    "        q.uns[f'{color_key}_colors'] = [ref_color_dict[_] for _ in q.obs[color_key].cat.categories]\n",
    "    return queries\n",
    "\n",
    "def get_umap(ad, use_reps=[]):\n",
    "    for use_rep in use_reps:\n",
    "        umap_add_key = f'{use_rep}_umap'\n",
    "        sc.pp.neighbors(ad, use_rep=use_rep, n_neighbors=15)\n",
    "        sc.tl.umap(ad)\n",
    "        ad.obsm[umap_add_key] = ad.obsm['X_umap']\n",
    "    return ad\n",
    "\n",
    "def wrap_warn_plot(adata, basis, color, **kwargs):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "        sc.pl.embedding(adata, basis=basis, color=color, **kwargs)\n",
    "\n",
    "def wrap_warn_comp_plot(ads, basis, colors, figw=5, figh=4, **kwargs):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        for i, color in enumerate(colors):\n",
    "            _, axes = plt.subplots(1, len(ads), figsize=(figw*len(ads), figh))\n",
    "            for j, ad in enumerate(ads):\n",
    "                sc.pl.embedding(ad, basis=basis, color=color, ax=axes[j], show=False, **kwargs)\n",
    "            plt.show()\n",
    "            \n",
    "os.environ['R_HOME'] = '/disco_500t/xuhua/miniforge3/envs/Seurat5/lib/R'\n",
    "os.environ['R_USER'] = '/disco_500t/xuhua/miniforge3/envs/Seurat5/lib/python3.8/site-packages/rpy2'\n",
    "def mclust_R(adata, num_cluster, modelNames='EEE', used_obsm='STAGATE', random_seed=2020):\n",
    "    np.random.seed(random_seed)\n",
    "    import rpy2.robjects as robjects\n",
    "    robjects.r.library(\"mclust\")\n",
    "\n",
    "    import rpy2.robjects.numpy2ri\n",
    "    rpy2.robjects.numpy2ri.activate()\n",
    "    r_random_seed = robjects.r['set.seed']\n",
    "    r_random_seed(random_seed)\n",
    "    rmclust = robjects.r['Mclust']\n",
    "\n",
    "    res = rmclust(rpy2.robjects.numpy2ri.numpy2rpy(adata.obsm[used_obsm]), num_cluster, modelNames)\n",
    "    mclust_res = np.array(res[-2])\n",
    "\n",
    "    adata.obs['mclust'] = mclust_res\n",
    "    adata.obs['mclust'] = adata.obs['mclust'].astype('int')\n",
    "    adata.obs['mclust'] = adata.obs['mclust'].astype('category')\n",
    "    return adata\n",
    "\n",
    "def load_h5(path):\n",
    "    with h5py.File(path, 'r') as f:\n",
    "        print(f['matrix'].keys())\n",
    "        print(f['matrix']['features'].keys())\n",
    "\n",
    "        barcodes = [_.decode('utf-8') for _ in f['matrix']['barcodes'][:]]\n",
    "        data = f['matrix']['data'][:]\n",
    "        indices = f['matrix']['indices'][:]\n",
    "        indptr = f['matrix']['indptr'][:]\n",
    "        shape = f['matrix']['shape'][:]\n",
    "\n",
    "        feature_type = [_.decode('utf-8') for _ in f['matrix']['features']['feature_type'][:]]\n",
    "        feature_id   = [_.decode('utf-8') for _ in f['matrix']['features']['id'][:]]\n",
    "        feature_name = [_.decode('utf-8') for _ in f['matrix']['features']['name'][:]]\n",
    "        feature_interval = [_.decode('utf-8') for _ in f['matrix']['features']['interval'][:]]\n",
    "\n",
    "\n",
    "        X = sps.csc_matrix(\n",
    "            (data, indices, indptr), \n",
    "            shape = shape\n",
    "        ).tocsc().astype(np.float32).T.toarray()\n",
    "\n",
    "        adata = sc.AnnData(X)\n",
    "        adata.obs_names = barcodes\n",
    "        adata.var_names = feature_id\n",
    "        adata.var['type'] = feature_type\n",
    "        adata.var['name'] = feature_name\n",
    "        adata.var['interval'] = feature_interval\n",
    "    return adata\n",
    "\n",
    "from scib.metrics import lisi\n",
    "def eval_lisi(\n",
    "        adata,\n",
    "        batch_keys=['domain', 'batch'],\n",
    "        label_keys = ['gt'],\n",
    "        use_rep='X_emb', use_neighbors=False,\n",
    "    ):\n",
    "    res = {}\n",
    "    for key in batch_keys:\n",
    "        adata.obs[key] = adata.obs[key].astype('category')\n",
    "\n",
    "        _lisi = lisi.ilisi_graph(\n",
    "            adata,\n",
    "            key,\n",
    "            'embed' if not use_neighbors else 'knn',\n",
    "            use_rep=use_rep,\n",
    "            k0=90,\n",
    "            subsample=None,\n",
    "            scale=True,\n",
    "            n_cores=1,\n",
    "            verbose=False,\n",
    "        )\n",
    "        res[key+'_iLISI'] = _lisi\n",
    "    for key in label_keys:\n",
    "        adata.obs[key] = adata.obs[key].astype('category')\n",
    "\n",
    "        _lisi = lisi.clisi_graph(\n",
    "            adata,\n",
    "            key,\n",
    "            'embed' if not use_neighbors else 'knn',\n",
    "            use_rep=use_rep,\n",
    "            batch_key=None,\n",
    "            k0=90,\n",
    "            subsample=None,\n",
    "            scale=True,\n",
    "            n_cores=1,\n",
    "            verbose=False,\n",
    "        )\n",
    "        res[key+'_cLISI'] = _lisi\n",
    "    df = pd.DataFrame.from_dict(res, orient='index').T\n",
    "    # df.columns = [_+'_LISI' for _ in df.columns]\n",
    "    return df\n",
    "\n",
    "def eval_ads(ads, ref_key, src_key):\n",
    "    aris = []\n",
    "    for ad in ads:\n",
    "        aris.append(adjusted_rand_score(ad.obs[src_key], ad.obs[ref_key]))\n",
    "    return aris\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "def eval_labelTransfer(ad1, ad2, use_rep, lab_key, knn=10):\n",
    "     with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "        neigh1 = KNeighborsClassifier(n_neighbors=knn)\n",
    "        neigh1.fit(ad1.obsm[use_rep], ad1.obs[lab_key].to_list())\n",
    "        pr_lab2 = neigh1.predict(ad2.obsm[use_rep])\n",
    "        f1_1 = f1_score(ad2.obs[lab_key].values, pr_lab2, #labels=['1.0', '2.0', '3.0', '4.0'], \n",
    "                        average='macro')\n",
    "        # acc1 = (pr_lab2 == ad2.obs[lab_key].values).mean()\n",
    "    \n",
    "        neigh2 = KNeighborsClassifier(n_neighbors=knn)\n",
    "        neigh2.fit(ad2.obsm[use_rep], ad2.obs[lab_key].to_list())\n",
    "        pr_lab1 = neigh2.predict(ad1.obsm[use_rep])\n",
    "        # acc2 = (pr_lab1 == ad1.obs[lab_key].values).mean()\n",
    "        f1_2 = f1_score(ad1.obs[lab_key].values, pr_lab1, #labels=['1.0', '2.0', '3.0', '4.0'], \n",
    "                        average='macro')\n",
    "        return (f1_1+f1_2)/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c9b2b5a-0d42-4ce6-b991-4f91f9382a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_ob(ads, ad_ref, ob='obs', key='emb2'):\n",
    "    len_ads = [_.n_obs for _ in ads]\n",
    "    if ob=='obsm':\n",
    "        split_obsms = np.split(ad_ref.obsm[key], np.cumsum(len_ads[:-1]))\n",
    "        for ad, v in zip(ads, split_obsms):\n",
    "            ad.obsm[key] = v\n",
    "    else:\n",
    "        split_obs = np.split(ad_ref.obs[key].to_list(), np.cumsum(len_ads[:-1]))\n",
    "        for ad, v in zip(ads, split_obs):\n",
    "            ad.obs[key] = v\n",
    "    \n",
    "def subset_ad(ad, subset_index):\n",
    "    ad = ad[subset_index].copy()\n",
    "    return ad\n",
    "\n",
    "def set_spatial(ad):\n",
    "    ad.obsm['spatial'] = ad.obs[['array_row', 'array_col']].values\n",
    "    ad.obsm['spatial'] = ad.obsm['spatial'][:, ::-1]\n",
    "    ad.obsm['spatial'][:, 1] = -1 * ad.obsm['spatial'][:, 1]\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6b399a-ad73-48bf-9161-7b4ebec63718",
   "metadata": {},
   "source": [
    "### load metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "056e1b54-a443-41bf-aa3d-5ff645238a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['barcodes', 'data', 'features', 'indices', 'indptr', 'shape']>\n",
      "<KeysViewHDF5 ['_all_tag_keys', 'feature_type', 'genome', 'id', 'interval', 'name']>\n",
      "<KeysViewHDF5 ['barcodes', 'data', 'features', 'indices', 'indptr', 'shape']>\n",
      "<KeysViewHDF5 ['_all_tag_keys', 'feature_type', 'genome', 'id', 'interval', 'name']>\n",
      "<KeysViewHDF5 ['barcodes', 'data', 'features', 'indices', 'indptr', 'shape']>\n",
      "<KeysViewHDF5 ['_all_tag_keys', 'feature_type', 'genome', 'id', 'interval', 'name']>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3685"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/disco_500t/xuhua/data/MISAR_seq/'\n",
    "ad_bridge = load_h5(join(data_dir, 'E15_5-S1_raw_feature_bc_matrix.h5'))\n",
    "ad_test1 = load_h5(join(data_dir, 'E18_5-S1_raw_feature_bc_matrix.h5'))\n",
    "ad_test2 = load_h5(join(data_dir, 'E18_5-S1_raw_feature_bc_matrix.h5'))  # inconsistent peak name across batches\n",
    "peak_mat = sps.csr_matrix(sio.mmread(join(data_dir, 'BaiduDisk/section1/peak_mat.mtx')).T)\n",
    "peak_spot_name = pd.read_csv(join(data_dir, 'BaiduDisk/section1/peak_spot_names.csv')).x.values\n",
    "\n",
    "meta = pd.read_csv(join(data_dir, 'BaiduDisk/section1/meta_data.csv'), index_col=0)\n",
    "\n",
    "ad_bridge.obs_names = [f'E15_5-S1#{_}' for _ in ad_bridge.obs_names]\n",
    "ad_test1.obs_names = [f'E18_5-S1#{_}' for _ in ad_test1.obs_names]\n",
    "ad_test2.obs_names = [f'E18_5-S1#{_}' for _ in ad_test2.obs_names]\n",
    "\n",
    "# split rna and peak\n",
    "ad_bridge_rna = ad_bridge[:, ad_bridge.var['type'] == 'Gene Expression'].copy()\n",
    "ad_test1_rna = ad_test1[:, ad_test1.var['type'] == 'Gene Expression'].copy()\n",
    "\n",
    "# subset peak matrices\n",
    "bridge_mask = np.in1d(peak_spot_name, ad_bridge.obs_names)\n",
    "ad_bridge_atac = sc.AnnData(peak_mat[bridge_mask])\n",
    "ad_bridge_atac.obs_names = peak_spot_name[bridge_mask]\n",
    "test2_mask = np.in1d(peak_spot_name, ad_test2.obs_names)\n",
    "ad_test2_atac = sc.AnnData(peak_mat[test2_mask])\n",
    "ad_test2_atac.obs_names = peak_spot_name[test2_mask]\n",
    "\n",
    "ad_bridge_rna = subset_ad(ad_bridge_rna, ad_bridge_rna.obs_names.intersection(meta.index))\n",
    "ad_test1_rna = subset_ad(ad_test1_rna, ad_test1_rna.obs_names.intersection(meta.index))\n",
    "\n",
    "ad_bridge_rna.obs = meta.loc[ad_bridge_rna.obs_names].copy()\n",
    "ad_bridge_atac.obs = meta.loc[ad_bridge_atac.obs_names].copy()\n",
    "ad_test1_rna.obs = meta.loc[ad_test1_rna.obs_names].copy()\n",
    "ad_test2_atac.obs = meta.loc[ad_test2_atac.obs_names].copy()\n",
    "ad_bridge_rna = set_spatial(ad_bridge_rna)\n",
    "ad_bridge_atac = set_spatial(ad_bridge_atac)\n",
    "ad_test1_rna = set_spatial(ad_test1_rna)\n",
    "ad_test2_atac = set_spatial(ad_test2_atac)\n",
    "\n",
    "set_col2cat(ad_bridge_rna, cols=['ATAC_Clusters', 'RNA_Clusters', 'Combined_Clusters', 'Sample'])\n",
    "set_col2cat(ad_bridge_atac, cols=['ATAC_Clusters', 'RNA_Clusters', 'Combined_Clusters', 'Sample'])\n",
    "set_col2cat(ad_test1_rna, cols=['ATAC_Clusters', 'RNA_Clusters', 'Combined_Clusters', 'Sample'])\n",
    "set_col2cat(ad_test2_atac, cols=['ATAC_Clusters', 'RNA_Clusters', 'Combined_Clusters', 'Sample'])\n",
    "\n",
    "del peak_mat, ad_bridge, ad_test1, ad_test2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d722bf8c-de5b-4455-9a2c-a1c5b27f7e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "ad_bridge_atac = ad_bridge_atac[ad_bridge_rna.obs_names].copy()\n",
    "assert (ad_bridge_rna.obs_names == ad_bridge_atac.obs_names).all()\n",
    "\n",
    "ad_test2_atac = ad_test2_atac[ad_test1_rna.obs_names].copy()\n",
    "print((ad_test1_rna.obs_names == ad_test2_atac.obs_names).all())\n",
    "\n",
    "ad_test1_rna.obs_names = [f'rna_{_}' for _ in ad_test1_rna.obs_names]\n",
    "ad_test2_atac.obs_names = [f'atac_{_}' for _ in ad_test2_atac.obs_names]\n",
    "\n",
    "ad_bridge_rna.obs['src'] = ad_bridge_atac.obs['src'] = ['s1']*ad_bridge_rna.n_obs\n",
    "ad_test1_rna.obs['src'] = ['s2-rna']*ad_test1_rna.n_obs\n",
    "ad_test2_atac.obs['src'] = ['s2-atac']*ad_test2_atac.n_obs\n",
    "ad_test1_rna.obs['Sample'] = ['S2']*ad_test1_rna.n_obs\n",
    "ad_test2_atac.obs['Sample'] = ['S2']*ad_test2_atac.n_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "552ed9e5-1298-48e4-ad2f-772a9d1e28c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./outputs/E15-18-18_modalMatch.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5829a77-4eae-4407-9415-e03b5ddf8492",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_bridge_rna.obsm['emb'] = df.loc[ad_bridge_rna.obs_names].values\n",
    "ad_test1_rna.obsm['emb']  = df.loc[ad_test1_rna.obs_names].values\n",
    "ad_test2_atac.obsm['emb'] = df.loc[ad_test2_atac.obs_names].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b3d144-cd55-4ac8-a93e-4832f4e412b5",
   "metadata": {},
   "source": [
    "### before harmony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35e83ebb-cacd-4539-b878-bdac3e3743da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ad_mosaic = sc.concat([ad_bridge_rna, ad_test1_rna, ad_test2_atac])\n",
    "# ad_mosaic = get_umap(ad_mosaic, ['emb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58a24d7d-063a-44b3-a376-d4072fdc5c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOSCTTM=0.50257\n",
      "Match_score=0.00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'FOSCTTM': 0.5025744372872238, 'Match_score': 3.0901584633259995e-06}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lisi_bridge import eval_bridge\n",
    "eval_bridge(\n",
    "        ad_test1_rna, ad_test2_atac,\n",
    "        label_key=None,\n",
    "        batch_key='Sample',\n",
    "        use_rep='emb',\n",
    "        use_fosc=True, use_acc=False, use_score=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b8d10c-0a95-4119-8781-c1ff6c2ccf3f",
   "metadata": {},
   "source": [
    "## after harmony"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e839dff-a49c-419e-b19f-a3b510aff920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU mode.\n",
      "\tInitialization is completed.\n",
      "\tCompleted 1 / 10 iteration(s).\n",
      "\tCompleted 2 / 10 iteration(s).\n",
      "\tCompleted 3 / 10 iteration(s).\n",
      "\tCompleted 4 / 10 iteration(s).\n",
      "Reach convergence after 4 iteration(s).\n"
     ]
    }
   ],
   "source": [
    "from postp import HARMONY\n",
    "\n",
    "ad_mosaic.obsm['emb_har'] = HARMONY(pd.DataFrame(ad_mosaic.obsm['emb']), ad_mosaic.obs.src.values)\n",
    "split_ob([ad_bridge_rna, ad_test1_rna, ad_test2_atac], ad_mosaic, ob='obsm',  key='emb_har')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5b30e86-91d3-4bde-ad80-92c3c63e81e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOSCTTM=0.49932\n",
      "Match_score=0.00000\n"
     ]
    }
   ],
   "source": [
    "### evaluation\n",
    "\n",
    "r3 = eval_bridge(\n",
    "        ad_test1_rna, ad_test2_atac,\n",
    "        label_key=None,\n",
    "        batch_key='Sample',\n",
    "        use_rep='emb_har',\n",
    "        use_fosc=True, use_acc=False, use_score=True,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eff6688-b27c-4c6a-b6c3-ea2462514ae3",
   "metadata": {},
   "source": [
    "## Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36d7db9c-af02-4efe-bbb2-b496e600046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dir = f'/disco_500t/xuhua/gitrepo/BridgeNorm/figures/misar_seq/E15-18-18_modalMatch/stabmap'\n",
    "os.makedirs(fig_dir, exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame(ad_mosaic.obsm['emb'], index=ad_bridge_rna.obs_names.to_list() + ad_test1_rna.obs_names.to_list() + ad_test2_atac.obs_names.to_list())\n",
    "# df['before_clust'] = ad_mosaic.obs['before_clust'].to_list() \n",
    "df.to_csv(join(fig_dir, 'X_emb.csv'))\n",
    "\n",
    "df = pd.DataFrame(ad_mosaic.obsm['emb_har'], index=ad_bridge_rna.obs_names.to_list() + ad_test1_rna.obs_names.to_list() + ad_test2_atac.obs_names.to_list())\n",
    "# df['after_clust'] = ad_mosaic.obs['after_clust'].to_list() \n",
    "df.to_csv(join(fig_dir, 'X_emb_har.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79951626-1737-4042-8fed-8626874cbcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42bc0b-867b-4b49-8bf8-28c10a23668b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Squidpy",
   "language": "python",
   "name": "squidpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
