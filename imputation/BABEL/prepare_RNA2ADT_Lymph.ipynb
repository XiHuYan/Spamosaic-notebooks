{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3a6673c-9388-4c03-81c7-720fedbccefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anndata as ad\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import csr_matrix, coo_matrix, csc_matrix\n",
    "from scipy.io import mmread, mmwrite\n",
    "import os\n",
    "import numpy as np\n",
    "from os.path import join\n",
    "from pathlib import Path, PurePath\n",
    "import gzip\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c42b6edc-f2bc-4e20-949b-732fa4477fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy\n",
    "from matplotlib.image import imread\n",
    "def load_spatial(path, adata, library_id='0'):\n",
    "    tissue_positions_file = join(path, \"tissue_positions.csv\")\n",
    "    files = dict(\n",
    "        tissue_positions_file=tissue_positions_file,\n",
    "        scalefactors_json_file=join(path, \"scalefactors_json.json\"),\n",
    "        hires_image=join(path, \"tissue_hires_image.png\"),\n",
    "        lowres_image=join(path, \"tissue_lowres_image.png\"),\n",
    "    )\n",
    "    \n",
    "    adata.uns[\"spatial\"] = dict()\n",
    "    adata.uns[\"spatial\"][library_id] = dict()\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"] = dict()\n",
    "    for res in [\"hires\", \"lowres\"]:\n",
    "        try:\n",
    "            adata.uns[\"spatial\"][library_id][\"images\"][res] = imread(\n",
    "                str(files[f\"{res}_image\"])\n",
    "            )\n",
    "        except Exception:\n",
    "            raise OSError(f\"Could not find '{res}_image'\")\n",
    "\n",
    "    # read json scalefactors\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"] = json.loads(\n",
    "        Path(files[\"scalefactors_json_file\"]).read_bytes()\n",
    "    )\n",
    "\n",
    "    # adata.uns[\"spatial\"][library_id][\"metadata\"] = {\n",
    "    #     k: (str(attrs[k], \"utf-8\") if isinstance(attrs[k], bytes) else attrs[k])\n",
    "    #     for k in (\"chemistry_description\", \"software_version\")\n",
    "    #     if k in attrs\n",
    "    # }\n",
    "\n",
    "    # read coordinates\n",
    "    positions = pd.read_csv(\n",
    "        files[\"tissue_positions_file\"],\n",
    "        header=0 if Path(tissue_positions_file).name == \"tissue_positions.csv\" else None,\n",
    "        index_col=0,\n",
    "    )\n",
    "    positions.columns = [\n",
    "        \"in_tissue\",\n",
    "        \"array_row\",\n",
    "        \"array_col\",\n",
    "        \"pxl_col_in_fullres\",\n",
    "        \"pxl_row_in_fullres\",\n",
    "    ]\n",
    "    # print(positions.head())\n",
    "\n",
    "    adata.obs = adata.obs.join(positions, how=\"left\")\n",
    "\n",
    "    adata.obsm[\"spatial\"] = adata.obs[\n",
    "        [\"pxl_row_in_fullres\", \"pxl_col_in_fullres\"]\n",
    "    ].to_numpy()\n",
    "   \n",
    "    adata.obs.drop(\n",
    "        columns=[\"pxl_row_in_fullres\", \"pxl_col_in_fullres\"],\n",
    "        inplace=True,\n",
    "    )\n",
    "\n",
    "def load_data(_dir):\n",
    "    feat_names = pd.read_csv(join(_dir, 'features.tsv.gz'), compression='gzip', sep='\\t', header=None)\n",
    "    barcodes   = pd.read_csv(join(_dir, 'barcodes.tsv.gz'), compression='gzip', sep='\\t', header=None)\n",
    "\n",
    "    with gzip.open(join(_dir, 'matrix.mtx.gz'), 'rb') as gzipped_file:\n",
    "        mat = mmread(gzipped_file)\n",
    "\n",
    "    ad = sc.AnnData(sps.csr_matrix(mat.T))\n",
    "    ad.obs_names = barcodes[0].values\n",
    "    ad.var_names = feat_names[1].values\n",
    "    ad.var['id'] = feat_names[0].values\n",
    "    ad.var['type'] = feat_names[2].values\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6582625c-b079-4753-b06c-93e97d958001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_new_ad(ad_rna, ad_adt, batch_key, dataset_id, species):\n",
    "    X = csr_matrix(ad_rna.X)\n",
    "    cell_names = pd.DataFrame(ad_rna.obs_names)\n",
    "    cell_names.columns = ['cell_ids']\n",
    "    gene_names = pd.DataFrame(ad_rna.var_names)\n",
    "    gene_names.columns = ['gene_ids']\n",
    "    input_train_mod1 = ad.AnnData(X, obs=pd.DataFrame(index=cell_names.cell_ids), var=pd.DataFrame(index = gene_names.gene_ids))\n",
    "    # input_train_mod1.var['gene_ids'] = input_train_mod1.var_names\n",
    "    input_train_mod1.var['feature_types'] = pd.Categorical(len(input_train_mod1.var_names)*['GEX'])\n",
    "    input_train_mod1.obs['batch'] = pd.Categorical(ad_rna.obs[batch_key].to_list())\n",
    "    input_train_mod1.uns = {\"dataset_id\": dataset_id, \"organism\": species}\n",
    "    input_train_mod1.layers['counts'] = input_train_mod1.X.copy()\n",
    "    \n",
    "    temp = csr_matrix(ad_adt.X)\n",
    "    obs_mod2 = pd.DataFrame(index = ad_adt.obs_names.to_list())\n",
    "    var_mod2 = pd.DataFrame(index = ad_adt.var_names.to_list())\n",
    "    input_train_mod2 = ad.AnnData(temp, obs=obs_mod2, var=var_mod2)\n",
    "    # input_train_mod2.var['gene_ids'] = input_train_mod2.var_names\n",
    "    input_train_mod2.var['feature_types'] = pd.Categorical(len(input_train_mod2.var_names)*['ADT'])\n",
    "    input_train_mod2.obs['batch'] = pd.Categorical(ad_adt.obs[batch_key].to_list())\n",
    "    input_train_mod2.uns = {\"dataset_id\": dataset_id, \"organism\": species}\n",
    "    input_train_mod2.layers['counts'] = input_train_mod2.X.copy()\n",
    "    return input_train_mod1, input_train_mod2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b88185cc-c2cd-4a3a-a781-353b06639219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n",
      "/home/xuhua/xuhua_disco/miniforge3/envs/Squidpy/lib/python3.8/site-packages/anndata/_core/anndata.py:1840: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/disco_500t/xuhua/data/spatial_multi_omics/lymp_node/LN-2024-new/outs'\n",
    "\n",
    "ad3 = load_data(join(data_dir, 'filtered_feature_bc_matrix'))\n",
    "ad3_rna = ad3[:, ad3.var['type']=='Gene Expression'].copy()\n",
    "ad3_adt = ad3[:, ad3.var['type']=='Antibody Capture'].copy()\n",
    "load_spatial(join(data_dir, 'spatial'), ad3_rna)\n",
    "load_spatial(join(data_dir, 'spatial'), ad3_adt)\n",
    "\n",
    "ad3_rna.obs['src'] = ad3_adt.obs['src'] = ['s3']*ad3_rna.n_obs\n",
    "ad3_rna.obs_names = [f's3-{x}' for x in ad3_rna.obs_names]\n",
    "ad3_adt.obs_names = [f's3-{x}' for x in ad3_adt.obs_names]\n",
    "\n",
    "ad3_rna.var_names_make_unique()\n",
    "ad3_adt.var_names_make_unique()\n",
    "\n",
    "data_dir = '/disco_500t/xuhua/data/spatial_multi_omics/lymp_tonsil_ramen'\n",
    "\n",
    "ad_a1_rna = sc.read_h5ad(join(data_dir, 'lymph_A1/adata_RNA.h5ad'))\n",
    "ad_a1_adt = sc.read_h5ad(join(data_dir, 'lymph_A1/adata_ADT.h5ad'))\n",
    "meta1 = pd.read_csv(join(data_dir, 'lymph_A1/A1_LN_cloupe_Kwoh.csv'), index_col=0) \n",
    "ad_a1_rna.obs['lab'] = meta1.loc[ad_a1_rna.obs_names, 'manual'].to_list()\n",
    "ad_a1_adt.obs['lab'] = meta1.loc[ad_a1_adt.obs_names, 'manual'].to_list()\n",
    "ad_a1_rna.obs['src'] = ad_a1_adt.obs['src'] = ['s1'] * ad_a1_rna.n_obs\n",
    "ad_a1_rna.obs_names = [f's1-{x}' for x in ad_a1_rna.obs_names]\n",
    "ad_a1_adt.obs_names = [f's1-{x}' for x in ad_a1_adt.obs_names]\n",
    "ad_a1_rna.var_names_make_unique()\n",
    "ad_a1_adt.var_names_make_unique()\n",
    "\n",
    "ad_d1_rna = sc.read_h5ad(join(data_dir, 'lymph_D1/adata_RNA.h5ad'))\n",
    "ad_d1_adt = sc.read_h5ad(join(data_dir, 'lymph_D1/adata_ADT.h5ad'))\n",
    "meta2 = pd.read_csv(join(data_dir, 'lymph_D1/D1_LN_cloupe_Kwoh.csv'), index_col=0) \n",
    "ad_d1_rna.obs['lab'] = meta2.loc[ad_d1_rna.obs_names, 'manual'].to_list()\n",
    "ad_d1_adt.obs['lab'] = meta2.loc[ad_d1_adt.obs_names, 'manual'].to_list()\n",
    "ad_d1_rna.obs['src'] = ad_d1_adt.obs['src'] = ['s2'] * ad_d1_rna.n_obs\n",
    "ad_d1_rna.obs_names = [f's2-{x}' for x in ad_d1_rna.obs_names]\n",
    "ad_d1_adt.obs_names = [f's2-{x}' for x in ad_d1_adt.obs_names]\n",
    "ad_d1_rna.var_names_make_unique()\n",
    "ad_d1_adt.var_names_make_unique()\n",
    "\n",
    "## unify feature names\n",
    "shared_gene = ad_a1_rna.var_names.intersection(ad_d1_rna.var_names).intersection(ad3_rna.var_names)\n",
    "shared_prot = ad_a1_adt.var_names.intersection(ad_d1_adt.var_names).intersection(ad3_adt.var_names)\n",
    "\n",
    "ad_a1_rna, ad_d1_rna, ad3_rna = ad_a1_rna[:, shared_gene].copy(), ad_d1_rna[:, shared_gene].copy(), ad3_rna[:, shared_gene].copy()\n",
    "ad_a1_adt, ad_d1_adt, ad3_adt = ad_a1_adt[:, shared_prot].copy(), ad_d1_adt[:, shared_prot].copy(), ad3_adt[:, shared_prot].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6e95b9a-3708-40a6-96fa-1d3d6666a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_rna_all = sc.concat([ad_a1_rna, ad_d1_rna, ad3_rna])\n",
    "ad_adt_all = sc.concat([ad_a1_adt, ad_d1_adt, ad3_adt])\n",
    "\n",
    "sc.pp.highly_variable_genes(ad_rna_all, batch_key=\"src\", flavor=\"seurat_v3\", n_top_genes=5000)\n",
    "\n",
    "ad_a1_rna = ad_a1_rna[:, ad_rna_all.var.query('highly_variable').index].copy()\n",
    "ad_d1_rna = ad_d1_rna[:, ad_rna_all.var.query('highly_variable').index].copy()\n",
    "ad3_rna = ad3_rna[:, ad_rna_all.var.query('highly_variable').index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e842644-b076-4ad4-96fa-b2f499b194e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNA_ADS = [ad_a1_rna, ad_d1_rna, ad3_rna]\n",
    "ADT_ADS = [ad_a1_adt, ad_d1_adt, ad3_adt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eee63f9-f714-432d-97c9-ab2c5c6d047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = '/disco_500t/xuhua/gitrepo/dance/data'\n",
    "for i in range(3):\n",
    "    tmp_path = join(work_dir, f'Lymph_cv{i+1}/')\n",
    "    os.makedirs(tmp_path+'openproblems_bmmc_cite_phase2_rna', exist_ok=True)\n",
    "\n",
    "    train_idx = list(set(np.arange(3)) - set({i}))\n",
    "    test_idx  = [i]\n",
    "    train_rna_data = sc.concat([RNA_ADS[idx] for idx in train_idx])\n",
    "    test_rna_data  = sc.concat([RNA_ADS[idx] for idx in test_idx])\n",
    "    train_adt_data = sc.concat([ADT_ADS[idx] for idx in train_idx])\n",
    "    test_adt_data  = sc.concat([ADT_ADS[idx] for idx in test_idx])\n",
    "\n",
    "    input_train_mod1, input_train_mod2 = create_new_ad(train_rna_data, train_adt_data, 'src', 'train', 'human')\n",
    "    input_test_mod1, input_test_mod2 = create_new_ad(test_rna_data, test_adt_data, 'src', 'test', 'human')\n",
    "\n",
    "    ## Store data to the specific location\n",
    "    input_train_mod1.write_h5ad(tmp_path + \"openproblems_bmmc_cite_phase2_rna/openproblems_bmmc_cite_phase2_rna.censor_dataset.output_train_mod1.h5ad\")\n",
    "    input_train_mod2.write_h5ad(tmp_path + \"openproblems_bmmc_cite_phase2_rna/openproblems_bmmc_cite_phase2_rna.censor_dataset.output_train_mod2.h5ad\")\n",
    "    input_test_mod1.write_h5ad(tmp_path + \"openproblems_bmmc_cite_phase2_rna/openproblems_bmmc_cite_phase2_rna.censor_dataset.output_test_mod1.h5ad\")\n",
    "    input_test_mod2.write_h5ad(tmp_path + \"openproblems_bmmc_cite_phase2_rna/openproblems_bmmc_cite_phase2_rna.censor_dataset.output_test_mod2.h5ad\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "518ccf3b-0dd0-4b0c-b036-1b2312fc507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def csv_read(path, header=True, index=True):\n",
    "    res = []\n",
    "    with open(path, mode='r', newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "\n",
    "        for i,row in enumerate(reader):\n",
    "            if header and i==0:\n",
    "                continue\n",
    "            try:\n",
    "                float_row = [float(item) for item in row]\n",
    "                if index:\n",
    "                    float_row = float_row[1:]\n",
    "                res.append(float_row)  # Each row is now a list of floats\n",
    "            except ValueError as e:\n",
    "                print(f\"Error converting to float: {e}\")\n",
    "    res = np.vstack(res)   \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f096b29-6ab4-42e2-a6aa-9227056b3b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3484, 31)\n",
      "(3359, 31)\n",
      "(3408, 31)\n"
     ]
    }
   ],
   "source": [
    "out_dir = '/disco_500t/xuhua/gitrepo/dance/output/RNA2ADT'\n",
    "\n",
    "for cv in range(3):\n",
    "    _dir = join(out_dir, f'Lymph_3slices_cv{cv+1}')\n",
    "    pr_X = csv_read(join(_dir, 'babel.csv'), index=True, header=True)\n",
    "    print(pr_X.shape)\n",
    "    ad_pr = sc.AnnData(pr_X, obs=ADT_ADS[cv].obs.copy(), var=ADT_ADS[cv].var.copy())\n",
    "    ad_pr.write_h5ad(f'/disco_500t/xuhua/gitrepo/BridgeNorm/figures/imputation/Lymph/babel/cv{cv+1}_imputedADT.h5ad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Squidpy",
   "language": "python",
   "name": "squidpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
