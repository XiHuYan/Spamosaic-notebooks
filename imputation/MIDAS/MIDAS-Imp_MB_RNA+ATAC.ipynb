{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d1dc554-89b4-4b0e-aa68-818103090b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import yaml\n",
    "import sys\n",
    "import h5py\n",
    "import logging\n",
    "import scanpy as sc\n",
    "from os.path import join\n",
    "import scipy.io as sio\n",
    "import scipy.sparse as sps\n",
    "from sklearn.cluster import KMeans\n",
    "import gzip\n",
    "from scipy.io import mmread\n",
    "from pathlib import Path, PurePath\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "\n",
    "import warnings\n",
    "def wrap_warn_plot(adata, basis, color, **kwargs):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "        sc.pl.embedding(adata, basis=basis, color=color, **kwargs)\n",
    "\n",
    "def get_umap(ad, use_reps=[]):\n",
    "    for use_rep in use_reps:\n",
    "        umap_add_key = f'{use_rep}_umap'\n",
    "        sc.pp.neighbors(ad, use_rep=use_rep, n_neighbors=15)\n",
    "        sc.tl.umap(ad)\n",
    "        ad.obsm[umap_add_key] = ad.obsm['X_umap']\n",
    "    return ad\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "def split_ob(ads, ad_ref, ob='obs', key='emb2'):\n",
    "    len_ads = [_.n_obs for _ in ads]\n",
    "    if ob=='obsm':\n",
    "        split_obsms = np.split(ad_ref.obsm[key], np.cumsum(len_ads[:-1]))\n",
    "        for ad, v in zip(ads, split_obsms):\n",
    "            ad.obsm[key] = v\n",
    "    else:\n",
    "        split_obs = np.split(ad_ref.obs[key].to_list(), np.cumsum(len_ads[:-1]))\n",
    "        for ad, v in zip(ads, split_obs):\n",
    "            ad.obs[key] = v\n",
    "\n",
    "def eval_ads(ads, ref_key, src_key, exclude=[]):\n",
    "    aris = []\n",
    "    for ad in ads:\n",
    "        _mask = ~ad.obs[ref_key].isin(exclude)\n",
    "        gt = ad.obs[ref_key].values[_mask]\n",
    "        pred = ad.obs[src_key].values[_mask]\n",
    "        aris.append(adjusted_rand_score(pred, gt))\n",
    "    return aris\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "def search_louvain(ad, use_rep, n_neighbors=15, n_clusters=5):\n",
    "    sc.pp.neighbors(ad, n_neighbors=n_neighbors, use_rep=use_rep)\n",
    "    rs = np.arange(0.1, 1.0, 0.1)\n",
    "    n_cs = []\n",
    "    for r in rs:\n",
    "        sc.tl.louvain(ad, resolution=r, key_added=f'r={r}')\n",
    "        n_cs.append(ad.obs[f'r={r}'].nunique())\n",
    "    n_cs = np.array(n_cs)\n",
    "    if (n_cs==n_clusters).sum() >= 1:\n",
    "        ri = np.where(n_cs==n_clusters)[0][0]\n",
    "        ad.obs['louvain_k'] = ad.obs[f'r={rs[ri]}'].to_list()\n",
    "    else:\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(ad.obsm[use_rep])\n",
    "        ad.obs['louvain_k'] = kmeans.labels_.astype('str')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "def eval_labelTransfer(ad1, ad2, use_rep, lab_key, knn=10):\n",
    "     with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
    "        neigh1 = KNeighborsClassifier(n_neighbors=knn)\n",
    "        neigh1.fit(ad1.obsm[use_rep], ad1.obs[lab_key].to_list())\n",
    "        pr_lab2 = neigh1.predict(ad2.obsm[use_rep])\n",
    "        f1_1 = f1_score(ad2.obs[lab_key].values, pr_lab2, #labels=['1.0', '2.0', '3.0', '4.0'], \n",
    "                        average='macro')\n",
    "        # acc1 = (pr_lab2 == ad2.obs[lab_key].values).mean()\n",
    "    \n",
    "        neigh2 = KNeighborsClassifier(n_neighbors=knn)\n",
    "        neigh2.fit(ad2.obsm[use_rep], ad2.obs[lab_key].to_list())\n",
    "        pr_lab1 = neigh2.predict(ad1.obsm[use_rep])\n",
    "        # acc2 = (pr_lab1 == ad1.obs[lab_key].values).mean()\n",
    "        f1_2 = f1_score(ad1.obs[lab_key].values, pr_lab1, #labels=['1.0', '2.0', '3.0', '4.0'], \n",
    "                        average='macro')\n",
    "        return (f1_1+f1_2)/2\n",
    "\n",
    "from scib.metrics import lisi\n",
    "def eval_lisi(\n",
    "        adata,\n",
    "        batch_keys=['domain', 'batch'],\n",
    "        label_keys = ['gt'],\n",
    "        use_rep='X_emb', use_neighbors=False,\n",
    "    ):\n",
    "    res = {}\n",
    "    for key in batch_keys:\n",
    "        adata.obs[key] = adata.obs[key].astype('category')\n",
    "\n",
    "        _lisi = lisi.ilisi_graph(\n",
    "            adata,\n",
    "            key,\n",
    "            'embed' if not use_neighbors else 'knn',\n",
    "            use_rep=use_rep,\n",
    "            k0=90,\n",
    "            subsample=None,\n",
    "            scale=True,\n",
    "            n_cores=1,\n",
    "            verbose=False,\n",
    "        )\n",
    "        res[key+'_iLISI'] = _lisi\n",
    "    for key in label_keys:\n",
    "        adata.obs[key] = adata.obs[key].astype('category')\n",
    "\n",
    "        _lisi = lisi.clisi_graph(\n",
    "            adata,\n",
    "            key,\n",
    "            'embed' if not use_neighbors else 'knn',\n",
    "            use_rep=use_rep,\n",
    "            batch_key=None,\n",
    "            k0=90,\n",
    "            subsample=None,\n",
    "            scale=True,\n",
    "            n_cores=1,\n",
    "            verbose=False,\n",
    "        )\n",
    "        res[key+'_cLISI'] = _lisi\n",
    "    df = pd.DataFrame.from_dict(res, orient='index').T\n",
    "    # df.columns = [_+'_LISI' for _ in df.columns]\n",
    "    return df\n",
    "\n",
    "os.environ['R_HOME'] = '/disco_500t/xuhua/miniforge3/envs/Seurat5/lib/R'\n",
    "os.environ['R_USER'] = '/disco_500t/xuhua/miniforge3/envs/Seurat5/lib/python3.8/site-packages/rpy2'\n",
    "def mclust_R(adata, num_cluster, modelNames='EEE', used_obsm='STAGATE', random_seed=2020):\n",
    "    np.random.seed(random_seed)\n",
    "    import rpy2.robjects as robjects\n",
    "    robjects.r.library(\"mclust\")\n",
    "\n",
    "    import rpy2.robjects.numpy2ri\n",
    "    rpy2.robjects.numpy2ri.activate()\n",
    "    r_random_seed = robjects.r['set.seed']\n",
    "    r_random_seed(random_seed)\n",
    "    rmclust = robjects.r['Mclust']\n",
    "\n",
    "    res = rmclust(rpy2.robjects.numpy2ri.numpy2rpy(adata.obsm[used_obsm]), num_cluster, modelNames)\n",
    "    mclust_res = np.array(res[-2])\n",
    "\n",
    "    adata.obs['mclust'] = mclust_res\n",
    "    adata.obs['mclust'] = adata.obs['mclust'].astype('int')\n",
    "    adata.obs['mclust'] = adata.obs['mclust'].astype('category')\n",
    "    return adata\n",
    "\n",
    "def load_data(_dir):\n",
    "    feat_names = pd.read_csv(join(_dir, 'features.tsv.gz'), compression='gzip', sep='\\t', header=None)\n",
    "    barcodes   = pd.read_csv(join(_dir, 'barcodes.tsv.gz'), compression='gzip', sep='\\t', header=None)\n",
    "\n",
    "    with gzip.open(join(_dir, 'matrix.mtx.gz'), 'rb') as gzipped_file:\n",
    "        mat = mmread(gzipped_file)\n",
    "\n",
    "    ad = sc.AnnData(sps.csr_matrix(mat.T))\n",
    "    ad.obs_names = barcodes[0].values\n",
    "    ad.var_names = feat_names[0].values\n",
    "    ad.var['name'] = feat_names[1].values\n",
    "    ad.var['type'] = feat_names[2].values\n",
    "    return ad\n",
    "\n",
    "import json\n",
    "import copy\n",
    "from matplotlib.image import imread\n",
    "def flip_coords(ads):\n",
    "    for ad in ads:\n",
    "        ad.obsm['spatial'] = -1 * ad.obsm['spatial']\n",
    "        ad.obsm['spatial'] = ad.obsm['spatial'][:, ::-1]\n",
    "\n",
    "def reorder(ad1, ad2):\n",
    "    shared_barcodes = ad1.obs_names.intersection(ad2.obs_names)\n",
    "    ad1 = ad1[shared_barcodes].copy()\n",
    "    ad2 = ad2[shared_barcodes].copy()\n",
    "    return ad1, ad2\n",
    "\n",
    "def load_peak_expr(_dir):\n",
    "    data = sio.mmread(join(_dir, 'data.mtx'))\n",
    "    cname = pd.read_csv(join(_dir, 'barcode.csv'), index_col=0)['x'].to_list()\n",
    "    feat = pd.read_csv(join(_dir, 'feat.csv'), index_col=0)['x'].to_list()\n",
    "    ad = sc.AnnData(sps.csr_matrix(data.T))\n",
    "    ad.obs_names = cname\n",
    "    ad.var_names = feat\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d8714e-be84-4896-8f6f-75574c3c536b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_col2cat(ad, cols=[]):\n",
    "    for col in cols:\n",
    "        ad.obs[col] = ad.obs[col].astype('category')\n",
    "\n",
    "def unify_colors(queries, color_key, ref_color_dict):\n",
    "    for q in queries:\n",
    "        q.obs[color_key] = q.obs[color_key].astype('category')\n",
    "        q.uns[f'{color_key}_colors'] = [ref_color_dict[_] for _ in q.obs[color_key].cat.categories]\n",
    "    return queries\n",
    "\n",
    "def subset_ad(ad, subset_index):\n",
    "    ad = ad[subset_index].copy()\n",
    "    return ad\n",
    "\n",
    "def set_spatial(ad):\n",
    "    ad.obsm['spatial'] = ad.obs[['array_row', 'array_col']].values\n",
    "    ad.obsm['spatial'] = ad.obsm['spatial'][:, ::-1]\n",
    "    ad.obsm['spatial'][:, 1] = -1 * ad.obsm['spatial'][:, 1]\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6706ddae-3067-4647-b21c-7a4e01fa3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def load_zu(_dir):\n",
    "    zs = []\n",
    "\n",
    "    for fi in sorted(os.listdir(_dir)):\n",
    "        dfi = pd.read_csv(join(_dir, fi), header=None)\n",
    "        zs.append(dfi.values)\n",
    "    zs = np.vstack(zs)\n",
    "    z, u = zs[:, :-2], zs[:, -2:]\n",
    "    return z, u\n",
    "\n",
    "def wrap_warn_plot(adata, basis, color, **kwargs):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=UserWarning)\n",
    "        sc.pl.embedding(adata, basis=basis, color=color, **kwargs)\n",
    "\n",
    "def get_umap(ad, use_reps=[]):\n",
    "    for use_rep in use_reps:\n",
    "        umap_add_key = f'{use_rep}_umap'\n",
    "        sc.pp.neighbors(ad, use_rep=use_rep, n_neighbors=15)\n",
    "        sc.tl.umap(ad)\n",
    "        ad.obsm[umap_add_key] = ad.obsm['X_umap']\n",
    "    return ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f60e017-d0b4-4a17-b9de-7a0a0bbf67cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dir = '/disco_500t/xuhua/gitrepo/midas/result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bec33661-beda-4631-bda0-694a7a0f7584",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/disco_500t/xuhua/data/real_mosaic_cases/mouse_brain_rna+atac/'\n",
    "\n",
    "df1_rna = pd.read_csv(join(data_dir, 'rna+atac/GSM6204636_MouseBrain_20um_matrix.tsv'), sep='\\t')\n",
    "df1_spatial_pos = pd.read_csv(join(data_dir, 'rna+atac/GSM6204623_MouseBrain_20um_spatial_rna_part/tissue_positions_list.csv'), header=None, index_col=0)\n",
    "ad1_rna = sc.AnnData(df1_rna.T, obsm={'spatial': df1_spatial_pos.loc[df1_rna.columns, [2, 3]].values})\n",
    "\n",
    "ad1_atac = load_peak_expr(join(data_dir, 'rna+atac/For_Imputation_Task/GSM6204623_peak_data'))\n",
    "df1_atac_spatial = pd.read_csv(join(data_dir, 'rna+atac/GSM6204623_MouseBrain_20um_spatial_rna_part/tissue_positions_list.csv'), index_col=0, header=None)\n",
    "ad1_atac.obsm['spatial'] = df1_atac_spatial.loc[ad1_atac.obs_names, [2, 3]].values\n",
    "ad1_rna, ad1_atac = reorder(ad1_rna, ad1_atac)\n",
    "\n",
    "# ===\n",
    "df2_rna = pd.read_csv(join(data_dir, 'rna+atac/GSM6753041_MouseBrain_20um_repATAC_matrix.tsv'), sep='\\t')\n",
    "df2_rna_spatial = pd.read_csv(join(data_dir, 'rna+atac/GSM6753041_MouseBrain_20um_repATAC_spatial/tissue_positions_list.csv'), index_col=0, header=None)\n",
    "ad2_rna = sc.AnnData(df2_rna.T, obsm={'spatial': df2_rna_spatial.loc[df2_rna.columns, [2, 3]].values})\n",
    "\n",
    "ad2_atac = load_peak_expr(join(data_dir, 'rna+atac/For_Imputation_Task/GSM6758284_peak_data'))\n",
    "df2_atac_spatial = pd.read_csv(join(data_dir, 'rna+atac//GSM6753041_MouseBrain_20um_repATAC_spatial/tissue_positions_list.csv'), index_col=0, header=None)\n",
    "ad2_atac.obsm['spatial'] = df2_atac_spatial.loc[ad2_atac.obs_names, [2, 3]].values\n",
    "ad2_rna, ad2_atac = reorder(ad2_rna, ad2_atac)\n",
    "\n",
    "# ===\n",
    "df3_rna = pd.read_csv(join(data_dir, 'rna+atac/GSM6753043_MouseBrain_20um_100barcodes_ATAC_matrix.tsv'), sep='\\t')\n",
    "df3_rna_spatial = pd.read_csv(join(data_dir, 'rna+atac/GSM6753043_MouseBrain_20um_100barcodes_ATAC_spatial/tissue_positions_list.csv'), index_col=0, header=None)\n",
    "ad3_rna = sc.AnnData(df3_rna.T, obsm={'spatial': df3_rna_spatial.loc[df3_rna.columns, [2, 3]].values})\n",
    "\n",
    "ad3_atac = load_peak_expr(join(data_dir, 'rna+atac/For_Imputation_Task/GSM6758285_peak_data'))\n",
    "df3_atac_spatial = pd.read_csv(join(data_dir, 'rna+atac//GSM6753043_MouseBrain_20um_100barcodes_ATAC_spatial/tissue_positions_list.csv'), index_col=0, header=None)\n",
    "ad3_atac.obsm['spatial'] = df3_atac_spatial.loc[ad3_atac.obs_names, [2, 3]].values\n",
    "ad3_rna, ad3_atac = reorder(ad3_rna, ad3_atac)\n",
    "\n",
    "shared_gene = ad1_rna.var_names.intersection(ad2_rna.var_names).intersection(ad3_rna.var_names)\n",
    "shared_peak = ad1_atac.var_names.intersection(ad2_atac.var_names).intersection(ad3_atac.var_names)\n",
    "ad1_rna = ad1_rna[:, shared_gene].copy(); ad2_rna = ad2_rna[:, shared_gene].copy(); ad3_rna = ad3_rna[:, shared_gene].copy()\n",
    "ad1_atac = ad1_atac[:, shared_peak].copy(); ad2_atac = ad2_atac[:, shared_peak].copy(); ad3_atac = ad3_atac[:, shared_peak].copy()\n",
    "\n",
    "ad1_rna.obs_names = [f's1-{_}' for _ in ad1_rna.obs_names]\n",
    "ad1_atac.obs_names = [f's1-{_}' for _ in ad1_atac.obs_names]\n",
    "ad2_rna.obs_names = [f's2-{_}' for _ in ad2_rna.obs_names]\n",
    "ad2_atac.obs_names = [f's2-{_}' for _ in ad2_atac.obs_names]\n",
    "ad3_rna.obs_names = [f's3-{_}' for _ in ad3_rna.obs_names]\n",
    "ad3_atac.obs_names = [f's3-{_}' for _ in ad3_atac.obs_names]\n",
    "\n",
    "ad1_rna.obs['src'] = ['s1']*ad1_rna.n_obs\n",
    "ad1_atac.obs['src'] = ['s1']*ad1_atac.n_obs\n",
    "ad2_rna.obs['src'] = ['s2']*ad2_rna.n_obs\n",
    "ad2_atac.obs['src'] = ['s2']*ad2_atac.n_obs\n",
    "ad3_rna.obs['src'] = ['s3']*ad3_rna.n_obs\n",
    "ad3_atac.obs['src'] = ['s3']*ad3_atac.n_obs\n",
    "\n",
    "ad1_rna.obsm['spatial'][:, 0] = -1 * ad1_rna.obsm['spatial'][:, 0]\n",
    "ad1_atac.obsm['spatial'][:, 0] = -1 * ad1_atac.obsm['spatial'][:, 0]\n",
    "ad2_rna.obsm['spatial'][:, 1] = -1 * ad2_rna.obsm['spatial'][:, 1]\n",
    "ad2_atac.obsm['spatial'][:, 1] = -1 * ad2_atac.obsm['spatial'][:, 1]\n",
    "ad3_rna.obsm['spatial'][:, 1] = -1 * ad3_rna.obsm['spatial'][:, 1]\n",
    "ad3_atac.obsm['spatial'][:, 1] = -1 * ad3_atac.obsm['spatial'][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b5abf2-1f2e-46ed-a66f-582f0ea5784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc.pp.normalize_total(ad3_rna, target_sum=1e4)\n",
    "# sc.pp.log1p(ad3_rna)\n",
    "# sc.pp.highly_variable_genes(ad3_rna, n_top_genes=5000)\n",
    "# ad3_rna_cp = ad3_rna[:, ad3_rna.var.query('highly_variable').index].copy()\n",
    "# sc.pp.pca(ad3_rna_cp, n_comps=50)\n",
    "# sc.pp.neighbors(ad3_rna_cp, n_neighbors=15)\n",
    "# sc.tl.umap(ad3_rna_cp)\n",
    "\n",
    "# wrap_warn_plot(ad1_rna, 'spatial', color=None, s=100)\n",
    "# wrap_warn_plot(ad2_rna, 'spatial', color=None, s=100)\n",
    "# wrap_warn_plot(ad3_rna, 'spatial', color=None, s=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7362372a-b576-4aac-ab5c-a092b3358b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_rna_all = sc.concat([ad1_rna, ad2_rna, ad3_rna])\n",
    "ad_atac_all = sc.concat([ad1_atac, ad2_atac, ad3_atac])\n",
    "\n",
    "sc.pp.highly_variable_genes(ad_rna_all, flavor='seurat_v3', n_top_genes=5000, batch_key='src')\n",
    "hvg_names = ad_rna_all.var.query('highly_variable').index.to_numpy()\n",
    "\n",
    "# ac.pp.tfidf(ad_atac_all, scale_factor=1e4)\n",
    "sc.pp.highly_variable_genes(ad_atac_all, flavor='seurat_v3', n_top_genes=50000, batch_key='src')\n",
    "hvp_names = ad_atac_all.var.query('highly_variable').index.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b331fcda-6a7b-401d-8641-ee9a03f02d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad1_rna = ad1_rna[:, hvg_names].copy(); ad1_atac = ad1_atac[:, hvp_names].copy()\n",
    "ad2_rna = ad2_rna[:, hvg_names].copy(); ad2_atac = ad2_atac[:, hvp_names].copy()\n",
    "ad3_rna = ad3_rna[:, hvg_names].copy(); ad3_atac = ad3_atac[:, hvp_names].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54d2f566-405c-4f67-b1c1-b093240a7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter feat names\n",
    "filtered_atac_feats = [_ for _ in ad1_atac.var_names if _.startswith('chr')]\n",
    "ad1_atac = ad1_atac[:, filtered_atac_feats].copy()\n",
    "ad2_atac = ad2_atac[:, filtered_atac_feats].copy()\n",
    "ad3_atac = ad3_atac[:, filtered_atac_feats].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68563c92-2f35-4a55-9f39-1cbed371905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list_byChr(input_list):\n",
    "    atac_name_chunks = []\n",
    "    for n in input_list:\n",
    "        chr = n.split(\"-\")[0]\n",
    "        if len(atac_name_chunks) == 0 or chr!=atac_name_chunks[-1]:\n",
    "            atac_name_chunks.append(chr)\n",
    "    return atac_name_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "055bb43a-6fa4-4852-ae05-8cab857deb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNA_ADS = [ad1_rna, ad2_rna, ad3_rna]\n",
    "ATAC_ADS = [ad1_atac, ad2_atac, ad3_atac]\n",
    "mod_dict = {'rna': RNA_ADS, 'atac':ATAC_ADS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c28ff0d4-34a0-4f40-881c-62c1508df66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2372, 5000) (2372, 49991)\n",
      "(2497, 5000) (2497, 49991)\n",
      "(9215, 5000) (9215, 49991)\n"
     ]
    }
   ],
   "source": [
    "for ad1, ad2 in zip(RNA_ADS, ATAC_ADS):\n",
    "    print(ad1.shape, ad2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31caae0c-5deb-4d02-9a97-e0fa8dde62c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):  # train test split\n",
    "    for mod in ['rna', 'atac']:   # missing mod\n",
    "        tmp_out_dir = f'/disco_500t/xuhua/gitrepo/midas/data/processed/MB_RNA_ATAC_cv{i+1}_missing{mod}'\n",
    "        print(tmp_out_dir)\n",
    "        feat_dir = join(tmp_out_dir, 'feat')\n",
    "        os.makedirs(feat_dir, exist_ok=True)\n",
    "        \n",
    "        atac_feat_chunks = split_list_byChr(ad1_atac.var_names) # split the chr-? in order\n",
    "        \n",
    "        atac_chr_count = Counter([_.split('-')[0] for _ in ad1_atac.var_names]) # count the frequency of each chr-?\n",
    "        df_feat_dims = pd.DataFrame(np.array([atac_chr_count[_] for _ in atac_feat_chunks]).reshape(-1, 1), columns=['atac'])\n",
    "        df_feat_dims['rna'] = ad1_rna.n_vars\n",
    "        df_feat_rna_names = pd.DataFrame(ad1_rna.var_names, columns=['x'])\n",
    "        df_feat_adt_names = pd.DataFrame(ad1_atac.var_names, columns=['x'])\n",
    "        df_feat_dims.to_csv(join(feat_dir, 'feat_dims.csv'))\n",
    "        df_feat_rna_names.to_csv(join(feat_dir, 'feat_names_rna.csv'))\n",
    "        df_feat_adt_names.to_csv(join(feat_dir, 'feat_names_atac.csv'))\n",
    "\n",
    "        # # each subset\n",
    "        subsets, mods = [], []\n",
    "        for bi in range(3):\n",
    "            tmp_set, tmp_mod = [], []\n",
    "            for bmod in ['rna', 'atac']:\n",
    "                if (bi==i) and (bmod == mod):\n",
    "                    continue\n",
    "                tmp_set.append(mod_dict[bmod][bi])\n",
    "                tmp_mod.append(bmod)\n",
    "            subsets.append(tmp_set)\n",
    "            mods.append(tmp_mod)\n",
    "        \n",
    "        # print(mods)\n",
    "        for si in range(3):\n",
    "            for fname in ['mask', 'mat', 'vec']:\n",
    "                os.makedirs(join(tmp_out_dir, f'subset_{si}/{fname}'), exist_ok=True)\n",
    "            tmp_dir = join(tmp_out_dir, f'subset_{si}')\n",
    "            for ad,mi in zip(subsets[si], mods[si]):\n",
    "                mat = ad.X.A if sps.issparse(ad.X) else ad.X\n",
    "                df_mat = pd.DataFrame(mat, index=ad.obs_names, columns=ad.var_names)\n",
    "                df_mat.to_csv(join(tmp_dir, f'mat/{mi}.csv'))\n",
    "        \n",
    "                os.makedirs(join(tmp_dir, f'vec/{mi}'), exist_ok=True)\n",
    "                for idx, mati in enumerate(mat):\n",
    "                    pd.DataFrame(mati.reshape(1, -1)).to_csv(join(tmp_dir, 'vec/{}/{:05d}.csv'.format(mi, idx)), header=None, index=None)\n",
    "                pd.DataFrame(ad.obs_names, columns=['x']).to_csv(join(tmp_dir, 'cell_names.csv'))\n",
    "        \n",
    "                # save mask\n",
    "                pd.DataFrame(np.ones(ad.n_vars, dtype='int')).to_csv(join(tmp_dir, f'mask/{mi}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f0101ee-e487-4c09-81a5-a4ab37d9326c",
   "metadata": {},
   "outputs": [],
   "source": [
    "e, ep = 1, 2000\n",
    "for i in range(3):  # train test split\n",
    "    for mod in ['rna', 'atac']:   # missing mod\n",
    "        training_command = f'CUDA_VISIBLE_DEVICES=1 python run.py --exp e{e} --task MB_RNA_ATAC_cv{i+1}_missing{mod} --epoch_num {ep}'\n",
    "    \n",
    "        run_command = 'CUDA_VISIBLE_DEVICES=1 python run.py --task MB_RNA_ATAC_cv{}_missing{} --act translate --init_model sp_{:08d} --exp e{}'\\\n",
    "                                    .format(i+1, mod, ep-1, e)\n",
    "        print(training_command)\n",
    "        print(run_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cfb87885-79ae-46eb-b2f8-87a1aa26bd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def csv_read(path):\n",
    "    res = []\n",
    "    with open(path, mode='r', newline='') as file:\n",
    "        reader = csv.reader(file)\n",
    "\n",
    "        for row in reader:\n",
    "            try:\n",
    "                float_row = [float(item) for item in row]\n",
    "                res.append(float_row)  # Each row is now a list of floats\n",
    "            except ValueError as e:\n",
    "                print(f\"Error converting to float: {e}\")\n",
    "    res = np.vstack(res)   \n",
    "    return res\n",
    "\n",
    "def collect_csv(_dir):\n",
    "    fls = sorted(os.listdir(_dir))\n",
    "    res = []\n",
    "    for fl in fls:\n",
    "        # df = pd.read_csv(join(_dir, fl), header=None)\n",
    "        data = csv_read(join(_dir, fl))\n",
    "        res.append(data)\n",
    "    res = np.vstack(res)\n",
    "    return res\n",
    "    \n",
    "import copy\n",
    "def binarize(Xs, bin_thr=0):\n",
    "    rs = []\n",
    "    for X in Xs:\n",
    "        X = copy.deepcopy(X.A) if sps.issparse(X) else copy.deepcopy(X)\n",
    "        X[X>bin_thr] = 1\n",
    "        rs.append(X)\n",
    "    return rs\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def eval_AUC_all(gt_X, pr_X, bin_thr=1):\n",
    "    gt_X = binarize([gt_X], bin_thr)[0].flatten()\n",
    "    pr_X = pr_X.flatten()\n",
    "    auroc = roc_auc_score(gt_X, pr_X)\n",
    "    return auroc\n",
    "\n",
    "def PCCs(gt_X, pr_X):\n",
    "    pcc_cell = [np.corrcoef(gt_X[i,:], pr_X[i,:])[0,1] for i in range(gt_X.shape[0])] \n",
    "    pcc_peak = [np.corrcoef(gt_X[:,i], pr_X[:,i])[0,1] for i in range(gt_X.shape[1])] \n",
    "    return pcc_cell, pcc_peak\n",
    "\n",
    "def cal_cmd(pred, true):\n",
    "    zero_rows_indices1 = list(np.where(~pred.any(axis=1))[0]) # all-zero rows\n",
    "    zero_rows_indices2 = list(np.where(~true.any(axis=1))[0])\n",
    "    zero_rows_indices = zero_rows_indices1 + zero_rows_indices2\n",
    "    rm_p = len(zero_rows_indices) / pred.shape[0]\n",
    "    if rm_p >= .05:\n",
    "        print(f'Warning: two many rows {rm_p}% with all zeros')\n",
    "    pred_array = pred[~np.isin(np.arange(pred.shape[0]), zero_rows_indices)].copy()\n",
    "    true_array = true[~np.isin(np.arange(true.shape[0]), zero_rows_indices)].copy()\n",
    "    corr_pred = np.corrcoef(pred_array,dtype=np.float32)\n",
    "    corr_true = np.corrcoef(true_array,dtype=np.float32)\n",
    "    \n",
    "    x = np.trace(corr_pred.dot(corr_true))\n",
    "    y = np.linalg.norm(corr_pred,'fro')*np.linalg.norm(corr_true,'fro')\n",
    "    cmd = 1- x/(y+1e-8)\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "824e6153-9ffe-4895-9cd3-e1c0381e68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/disco_500t/xuhua/gitrepo/midas/result'\n",
    "for i in range(3):\n",
    "    pr_atac = collect_csv(join(out_dir, f'MB_RNA_ATAC_cv{i+1}_missingatac/e1/default/predict/sp_00001999/subset_{i}/x_trans/rna_to_atac'))\n",
    "    gt_atac = ATAC_ADS[i].X.A if sps.issparse(ATAC_ADS[i].X) else ATAC_ADS[i].X\n",
    "\n",
    "    ad_pred = sc.AnnData(pr_atac, obs=ATAC_ADS[i].obs.copy())\n",
    "    ad_pred.var_names = ATAC_ADS[i].var_names.copy()\n",
    "    ad_pred.write_h5ad(f'/disco_500t/xuhua/gitrepo/BridgeNorm/figures/imputation/3slices_MB_RNA+ATAC/midas/cv{i+1}_imputedATAC.h5ad')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Squidpy",
   "language": "python",
   "name": "squidpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
