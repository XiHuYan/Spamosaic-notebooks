{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0f42348-b716-447d-9233-1661de3cb050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " UserWarning:/home/xuhua/xuhua_disco/miniforge3/envs/scButterfly/lib/python3.9/site-packages/torch/nn/_reduction.py:42: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
      "Global seed set to 0\n",
      " LightningDeprecationWarning:/home/xuhua/xuhua_disco/miniforge3/envs/scButterfly/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:53: pytorch_lightning.utilities.warnings.rank_zero_deprecation has been deprecated in v1.6 and will be removed in v1.8. Use the equivalent function from the pytorch_lightning.utilities.rank_zero module instead.\n",
      " LightningDeprecationWarning:/home/xuhua/xuhua_disco/miniforge3/envs/scButterfly/lib/python3.9/site-packages/pytorch_lightning/utilities/warnings.py:58: The `pytorch_lightning.loggers.base.rank_zero_experiment` is deprecated in v1.7 and will be removed in v1.9. Please use `pytorch_lightning.loggers.logger.rank_zero_experiment` instead.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "from os.path import join\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.io import mmread\n",
    "from scButterfly.train_model_cite import Model\n",
    "import gzip \n",
    "from pathlib import Path, PurePath\n",
    "import torch\n",
    "import scvi\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d853cef6-6936-4b14-8d79-5962ee66aeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(_dir):\n",
    "    feat_names = pd.read_csv(join(_dir, 'features.tsv.gz'), compression='gzip', sep='\\t', header=None)\n",
    "    barcodes   = pd.read_csv(join(_dir, 'barcodes.tsv.gz'), compression='gzip', sep='\\t', header=None)\n",
    "\n",
    "    with gzip.open(join(_dir, 'matrix.mtx.gz'), 'rb') as gzipped_file:\n",
    "        mat = mmread(gzipped_file)\n",
    "\n",
    "    ad = sc.AnnData(sps.csr_matrix(mat.T))\n",
    "    ad.obs_names = barcodes[0].values\n",
    "    ad.var_names = feat_names[1].values\n",
    "    ad.var['id'] = feat_names[0].values\n",
    "    ad.var['type'] = feat_names[2].values\n",
    "    return ad\n",
    "\n",
    "import json\n",
    "import copy\n",
    "from matplotlib.image import imread\n",
    "def load_spatial(path, adata, library_id='0'):\n",
    "    tissue_positions_file = join(path, \"tissue_positions.csv\")\n",
    "    files = dict(\n",
    "        tissue_positions_file=tissue_positions_file,\n",
    "        scalefactors_json_file=join(path, \"scalefactors_json.json\"),\n",
    "        hires_image=join(path, \"tissue_hires_image.png\"),\n",
    "        lowres_image=join(path, \"tissue_lowres_image.png\"),\n",
    "    )\n",
    "    \n",
    "    adata.uns[\"spatial\"] = dict()\n",
    "    adata.uns[\"spatial\"][library_id] = dict()\n",
    "    adata.uns[\"spatial\"][library_id][\"images\"] = dict()\n",
    "    for res in [\"hires\", \"lowres\"]:\n",
    "        try:\n",
    "            adata.uns[\"spatial\"][library_id][\"images\"][res] = imread(\n",
    "                str(files[f\"{res}_image\"])\n",
    "            )\n",
    "        except Exception:\n",
    "            raise OSError(f\"Could not find '{res}_image'\")\n",
    "\n",
    "    # read json scalefactors\n",
    "    adata.uns[\"spatial\"][library_id][\"scalefactors\"] = json.loads(\n",
    "        Path(files[\"scalefactors_json_file\"]).read_bytes()\n",
    "    )\n",
    "\n",
    "    # read coordinates\n",
    "    positions = pd.read_csv(\n",
    "        files[\"tissue_positions_file\"],\n",
    "        header=0 if Path(tissue_positions_file).name == \"tissue_positions.csv\" else None,\n",
    "        index_col=0,\n",
    "    )\n",
    "    positions.columns = [\n",
    "        \"in_tissue\",\n",
    "        \"array_row\",\n",
    "        \"array_col\",\n",
    "        \"pxl_col_in_fullres\",\n",
    "        \"pxl_row_in_fullres\",\n",
    "    ]\n",
    "    # print(positions.head())\n",
    "\n",
    "    adata.obs = adata.obs.join(positions, how=\"left\")\n",
    "\n",
    "    adata.obsm[\"spatial\"] = adata.obs[\n",
    "        [\"pxl_row_in_fullres\", \"pxl_col_in_fullres\"]\n",
    "    ].to_numpy()\n",
    "   \n",
    "    adata.obs.drop(\n",
    "        columns=[\"pxl_row_in_fullres\", \"pxl_col_in_fullres\"],\n",
    "        inplace=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b809a0-d16f-4ea8-b769-b86ecb4dcc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/disco_500t/xuhua/data/spatial_multi_omics/lymp_node/LN-2024-new/outs'\n",
    "\n",
    "ad3 = load_data(join(data_dir, 'filtered_feature_bc_matrix'))\n",
    "ad3_rna = ad3[:, ad3.var['type']=='Gene Expression'].copy()\n",
    "ad3_adt = ad3[:, ad3.var['type']=='Antibody Capture'].copy()\n",
    "load_spatial(join(data_dir, 'spatial'), ad3_rna)\n",
    "load_spatial(join(data_dir, 'spatial'), ad3_adt)\n",
    "\n",
    "ad3_rna.obs['src'] = ad3_adt.obs['src'] = ['s3']*ad3_rna.n_obs\n",
    "ad3_rna.obs_names = [f's3-{x}' for x in ad3_rna.obs_names]\n",
    "ad3_adt.obs_names = [f's3-{x}' for x in ad3_adt.obs_names]\n",
    "\n",
    "ad3_rna.var_names_make_unique()\n",
    "ad3_adt.var_names_make_unique()\n",
    "\n",
    "data_dir = '/disco_500t/xuhua/data/spatial_multi_omics/lymp_tonsil_ramen'\n",
    "\n",
    "ad_a1_rna = sc.read_h5ad(join(data_dir, 'lymph_A1/adata_RNA.h5ad'))\n",
    "ad_a1_adt = sc.read_h5ad(join(data_dir, 'lymph_A1/adata_ADT.h5ad'))\n",
    "meta1 = pd.read_csv(join(data_dir, 'lymph_A1/A1_LN_cloupe_Kwoh.csv'), index_col=0) \n",
    "ad_a1_rna.obs['lab'] = meta1.loc[ad_a1_rna.obs_names, 'manual'].to_list()\n",
    "ad_a1_adt.obs['lab'] = meta1.loc[ad_a1_adt.obs_names, 'manual'].to_list()\n",
    "ad_a1_rna.obs['src'] = ad_a1_adt.obs['src'] = ['s1'] * ad_a1_rna.n_obs\n",
    "ad_a1_rna.obs_names = [f's1-{x}' for x in ad_a1_rna.obs_names]\n",
    "ad_a1_adt.obs_names = [f's1-{x}' for x in ad_a1_adt.obs_names]\n",
    "ad_a1_rna.var_names_make_unique()\n",
    "ad_a1_adt.var_names_make_unique()\n",
    "\n",
    "ad_d1_rna = sc.read_h5ad(join(data_dir, 'lymph_D1/adata_RNA.h5ad'))\n",
    "ad_d1_adt = sc.read_h5ad(join(data_dir, 'lymph_D1/adata_ADT.h5ad'))\n",
    "meta2 = pd.read_csv(join(data_dir, 'lymph_D1/D1_LN_cloupe_Kwoh.csv'), index_col=0) \n",
    "ad_d1_rna.obs['lab'] = meta2.loc[ad_d1_rna.obs_names, 'manual'].to_list()\n",
    "ad_d1_adt.obs['lab'] = meta2.loc[ad_d1_adt.obs_names, 'manual'].to_list()\n",
    "ad_d1_rna.obs['src'] = ad_d1_adt.obs['src'] = ['s2'] * ad_d1_rna.n_obs\n",
    "ad_d1_rna.obs_names = [f's2-{x}' for x in ad_d1_rna.obs_names]\n",
    "ad_d1_adt.obs_names = [f's2-{x}' for x in ad_d1_adt.obs_names]\n",
    "ad_d1_rna.var_names_make_unique()\n",
    "ad_d1_adt.var_names_make_unique()\n",
    "\n",
    "## unify feature names\n",
    "shared_gene = ad_a1_rna.var_names.intersection(ad_d1_rna.var_names).intersection(ad3_rna.var_names)\n",
    "shared_prot = ad_a1_adt.var_names.intersection(ad_d1_adt.var_names).intersection(ad3_adt.var_names)\n",
    "\n",
    "ad_a1_rna, ad_d1_rna, ad3_rna = ad_a1_rna[:, shared_gene].copy(), ad_d1_rna[:, shared_gene].copy(), ad3_rna[:, shared_gene].copy()\n",
    "ad_a1_adt, ad_d1_adt, ad3_adt = ad_a1_adt[:, shared_prot].copy(), ad_d1_adt[:, shared_prot].copy(), ad3_adt[:, shared_prot].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14f86ff1-4d90-4af1-a6ba-3ced6b5f525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_rna_all = sc.concat([ad_a1_rna, ad_d1_rna, ad3_rna])\n",
    "ad_adt_all = sc.concat([ad_a1_adt, ad_d1_adt, ad3_adt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07734ed2-021c-4118-99a2-5f8ac7429a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pp.highly_variable_genes(ad_rna_all, batch_key=\"src\", flavor=\"seurat_v3\", n_top_genes=5000)\n",
    "\n",
    "ad_a1_rna = ad_a1_rna[:, ad_rna_all.var.query('highly_variable').index].copy()\n",
    "ad_d1_rna = ad_d1_rna[:, ad_rna_all.var.query('highly_variable').index].copy()\n",
    "ad3_rna = ad3_rna[:, ad_rna_all.var.query('highly_variable').index].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4411675a-eda7-4ca1-a48f-30f37da700bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNA_ADS = [ad_a1_rna, ad_d1_rna, ad3_rna]\n",
    "ADT_ADS = [ad_a1_adt, ad_d1_adt, ad3_adt]\n",
    "n_batches = 3\n",
    "IDS = [np.arange(ad_a1_rna.n_obs), ad_a1_rna.n_obs + np.arange(ad_d1_rna.n_obs), ad_a1_rna.n_obs+ad_d1_rna.n_obs+np.arange(ad3_rna.n_obs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e4984ee-e5e1-4d35-b6a9-14a3e13e135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"./Lymph/\" #path to results\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "751c0093-5d20-4d57-8d5a-306c944152ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from scipy.stats import pearsonr\n",
    "# for ad in ADT_ADS:\n",
    "#     new_X = np.ceil(ad.X.A / 1000)\n",
    "#     pccs = []\n",
    "#     for col in range(new_X.shape[1]):\n",
    "#         x, y = ad.X.A[:, col], new_X[:, col]\n",
    "#         pccs.append(pearsonr(x,y)[0])\n",
    "#     print(np.mean(pccs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "516513ac-9460-451a-ba7e-871faa8e86b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for ad in ADT_ADS:\n",
    "    ad.X = np.ceil(ad.X.A / 1000)  # to avoid numerical problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d569331-a29f-4b3a-bc7d-c0526ffce19c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s2' 's3']\n",
      "\u001b[34mINFO    \u001b[0m Using column names from columns of adata.obsm\u001b[1m[\u001b[0m\u001b[32m'protein_expression'\u001b[0m\u001b[1m]\u001b[0m                                       \n",
      "\u001b[34mINFO    \u001b[0m Found batches with missing protein expression                                                             \n",
      "\u001b[34mINFO    \u001b[0m Computing empirical prior initialization for protein background.                                          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 130/400:  32%|██▎    | 130/400 [03:46<07:23,  1.64s/it, loss=637, v_num=1]Epoch 00130: reducing learning rate of group 0 to 2.4000e-03.\n",
      "Epoch 144/400:  36%|██▌    | 144/400 [04:09<07:23,  1.73s/it, loss=623, v_num=1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 1273.287. Signaling Trainer to stop.\n",
      "['s1' 's3']\n",
      "\u001b[34mINFO    \u001b[0m Using column names from columns of adata.obsm\u001b[1m[\u001b[0m\u001b[32m'protein_expression'\u001b[0m\u001b[1m]\u001b[0m                                       \n",
      "\u001b[34mINFO    \u001b[0m Found batches with missing protein expression                                                             \n",
      "\u001b[34mINFO    \u001b[0m Computing empirical prior initialization for protein background.                                          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/400:  36%|██▌    | 143/400 [04:05<06:54,  1.61s/it, loss=621, v_num=1]Epoch 00143: reducing learning rate of group 0 to 2.4000e-03.\n",
      "Epoch 157/400:  39%|██▋    | 157/400 [04:27<06:54,  1.71s/it, loss=617, v_num=1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 1275.586. Signaling Trainer to stop.\n",
      "['s1' 's2']\n",
      "\u001b[34mINFO    \u001b[0m Using column names from columns of adata.obsm\u001b[1m[\u001b[0m\u001b[32m'protein_expression'\u001b[0m\u001b[1m]\u001b[0m                                       \n",
      "\u001b[34mINFO    \u001b[0m Found batches with missing protein expression                                                             \n",
      "\u001b[34mINFO    \u001b[0m Computing empirical prior initialization for protein background.                                          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/400:  33%|██▎    | 133/400 [03:46<06:56,  1.56s/it, loss=601, v_num=1]Epoch 00133: reducing learning rate of group 0 to 2.4000e-03.\n",
      "Epoch 147/400:  37%|██▌    | 147/400 [04:08<07:07,  1.69s/it, loss=628, v_num=1]\n",
      "Monitored metric elbo_validation did not improve in the last 45 records. Best score: 1272.048. Signaling Trainer to stop.\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_batches):\n",
    "    RNA_data = sc.concat(RNA_ADS)\n",
    "    ADT_data = []\n",
    "    train_ids = []\n",
    "    for bi in range(n_batches):\n",
    "        if bi==i:\n",
    "            ad_empty = sc.AnnData(np.zeros(ADT_ADS[bi].shape), obs=ADT_ADS[bi].obs.copy())\n",
    "            ad_empty.var_names = ADT_ADS[bi].var_names\n",
    "            ADT_data.append(ad_empty)\n",
    "            test_ids = list(IDS[bi])\n",
    "        else:\n",
    "            ADT_data.append(ADT_ADS[bi])\n",
    "            train_ids.append(IDS[bi])\n",
    "    ADT_data = sc.concat(ADT_data)\n",
    "    train_ids = list(np.hstack(train_ids))\n",
    "\n",
    "    RNA_data.obsm['protein_expression'] = ADT_data.to_df()\n",
    "    train_batches = RNA_data[train_ids].obs['src'].unique()\n",
    "    print(train_batches)\n",
    "\n",
    "    scvi.model.TOTALVI.setup_anndata(RNA_data, batch_key=\"src\", protein_expression_obsm_key=\"protein_expression\")\n",
    "    \n",
    "    model = scvi.model.TOTALVI(\n",
    "        RNA_data,\n",
    "        latent_distribution=\"normal\",\n",
    "        n_layers_decoder=2\n",
    "    )\n",
    "    model.train()\n",
    "    \n",
    "    RNA_data.obsm[\"X_totalVI\"] = model.get_latent_representation()\n",
    "    RNA_data.obsm[\"protein_fg_prob\"] = model.get_protein_foreground_probability(transform_batch=train_batches)\n",
    "    _, protein_means = model.get_normalized_expression(\n",
    "        n_samples=25,\n",
    "        transform_batch=train_batches,\n",
    "        include_protein_background=True,\n",
    "        sample_protein_mixing=False,\n",
    "        return_mean=True,\n",
    "    )\n",
    "    \n",
    "    protein = protein_means.iloc[test_ids]\n",
    "    ad_pred = sc.AnnData(protein, obs=ADT_data[test_ids].obs.copy())\n",
    "    ad_pred.var_names = ADT_data.var_names\n",
    "    ad_pred.write_h5ad(join(output_path, f'cv{i}_imputedADT.h5ad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62925169-fdb7-42c1-b231-f8ee09b938e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e298f22-d7ec-4d72-845f-16954f3421f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4cd47d-0768-4a06-9352-c622c3094ec9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scButterfly",
   "language": "python",
   "name": "scbutterfly"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
